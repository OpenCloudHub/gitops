apiVersion: ray.io/v1
kind: RayService
metadata:
  name: qwen-llm-service
  namespace: models
spec:
  serviceUnhealthySecondThreshold: 900
  deploymentUnhealthySecondThreshold: 300
  serveConfigV2: |
    applications:
      - name: qwen-llm
        import_path: ray.serve.llm:build_openai_app
        route_prefix: /
        args:
          llm_configs:
            - model_loading_config:
                model_id: qwen2.5-0.5b-instruct
                model_source: Qwen/Qwen2.5-0.5B-Instruct
              engine_kwargs:
                dtype: float16
                max_model_len: 1024
                gpu_memory_utilization: 0.4  # 40% of GPU memory for model+KV cache
                enforce_eager: true  # Disable CUDA graphs to reduce memory
                use_tqdm_on_load: false
                otlp_traces_endpoint: "grpc://k8s-monitoring-alloy-receiver.observability.svc.cluster.local:4317"
              deployment_config:
                autoscaling_config:
                  min_replicas: 1
                  max_replicas: 1   # Could Scale this up later
                  target_ongoing_requests: 4
                max_ongoing_requests: 8
              # Fractional GPU configuration
              placement_group_config:
                bundles:
                  - GPU: 0.49  # Use ~49% GPU (leave headroom)
              runtime_env:
                env_vars:
                  VLLM_USE_V1: "1"
                  VLLM_RAY_PER_WORKER_GPUS: "0.49"  # Must match placement_group_config
                  VLLM_DISABLE_COMPILE_CACHE: "1"  # Avoid resource contention
                  # OpenTelemetry configuration
                  OTEL_SERVICE_NAME: "qwen-llm-vllm"
                  OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: "grpc://k8s-monitoring-alloy-receiver.observability.svc.cluster.local:4317"
                  OTEL_EXPORTER_OTLP_TRACES_INSECURE: "true"
  rayClusterConfig:
    rayVersion: "2.51.0"
    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
        metrics-export-port: "8080"
        num-cpus: "0"
        num-gpus: "0"
      template:
        spec:
          containers:
            - name: ray-head
              image: rayproject/ray-llm:2.51.0-py311-cu128
              resources:
                requests:
                  cpu: "1"
                  memory: "2Gi"
                limits:
                  cpu: "2"
                  memory: "4Gi"
              env:
                - name: RAY_GRAFANA_HOST
                  value: "http://grafana.observability.svc.cluster.local:80"
                - name: RAY_PROMETHEUS_HOST
                  value: "http://prometheus-server.observability.svc.cluster.local:80"
                - name: RAY_GRAFANA_IFRAME_HOST
                  value: "https://grafana.internal.opencloudhub.org"
    workerGroupSpecs:
      - groupName: gpu-workers
        replicas: 1
        minReplicas: 1
        maxReplicas: 1
        numOfHosts: 1
        rayStartParams:
          num-gpus: "1" # Worker HAS 1 physical GPU
        template:
          spec:
            containers:
              - name: ray-worker
                image: rayproject/ray-llm:2.51.0-py311-cu128
                resources:
                  requests:
                    cpu: "4"
                    memory: "8Gi"
                    nvidia.com/gpu: "1"
                  limits:
                    cpu: "6"
                    memory: "12Gi"
                    nvidia.com/gpu: "1"
                env:
                  - name: OMP_NUM_THREADS
                    value: "4"
---
apiVersion: v1
kind: Service
metadata:
  name: qwen-llm
  namespace: models
  labels:
    app.kubernetes.io/name: qwen-llm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8000
      targetPort: 8000
      protocol: TCP
  selector:
    ray.io/cluster: qwen-llm-service-raycluster
    ray.io/node-type: head

---
# HTTPRoute for Qwen 0.5B LLM API
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: qwen-0.5b-api-route
  namespace: models
  labels:
    app.kubernetes.io/name: qwen-llm
    app.kubernetes.io/component: api-route
spec:
  parentRefs:
    - group: gateway.networking.k8s.io
      kind: Gateway
      name: ingress-gateway
      namespace: istio-ingress
  hostnames:
    - "api.opencloudhub.org"
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /models/base/qwen-0.5b/v1
      filters:
        - type: URLRewrite
          urlRewrite:
            path:
              type: ReplacePrefixMatch
              replacePrefixMatch: /v1
      backendRefs:
        - group: ""
          kind: Service
          name: qwen-llm-service-serve-svc
          port: 8000
          weight: 1

---
# HTTPRoute for Ray Dashboard
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: qwen-0.5b-dashboard-route
  namespace: models
  labels:
    app.kubernetes.io/name: qwen-llm
    app.kubernetes.io/component: dashboard-route
spec:
  parentRefs:
    - group: gateway.networking.k8s.io
      kind: Gateway
      name: ingress-gateway
      namespace: istio-ingress
  hostnames:
    - "qwen-0.5b.dashboard.opencloudhub.org"
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: "/"
      backendRefs:
        - group: ""
          kind: Service
          name: qwen-llm-service-head-svc
          port: 8265
          weight: 1
