apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: data-pipeline
  namespace: mlops
  annotations:
    workflows.argoproj.io/title: "**Data Pipeline**"
    workflows.argoproj.io/description: "Run DVC data pipelines with automatic versioning"
spec:
  serviceAccountName: workflow-executor
  generateName: "data-pipeline-{{workflow.parameters.dataset_name}}-"
  arguments:
    parameters:
      - name: dataset_name
        description: "Dataset identifier for workflow naming (e.g., readmes, embeddings)"
        value: "dataset"
      - name: pipelines
        description: "JSON array of pipeline names to run"
        value: '["opencloudhub-readmes-download"]'
      - name: force
        description: "Force re-run even if no changes"
        value: "false"
      - name: bump_type
        description: "Version bump type: major, minor, patch"
        value: "patch"
      - name: is_automated
        description: "Add -automated suffix to tags"
        value: "false"
      - name: image
        description: "Docker image for DVC operations"
        value: "opencloudhuborg/data-registry-pipelines:latest"
      - name: compute_type
        description: "Resource profile for pipeline execution"
        enum:
          [
            cpu-small,
            cpu-small-distributed,
            cpu-medium,
            cpu-large,
            gpu-small,
            gpu-medium,
            gpu-large,
          ]
        value: "cpu-small"

  entrypoint: main

  templates:
    # =========================================================================
    # Main: map compute, then fan out to run each pipeline in parallel
    # =========================================================================
    - name: main
      dag:
        tasks:
          - name: map-compute
            templateRef:
              name: compute-templates
              template: map-compute-config
            arguments:
              parameters:
                - name: compute_type
                  value: "{{workflow.parameters.compute_type}}"

          - name: run-pipelines
            depends: "map-compute.Succeeded"
            template: run-pipeline-with-resources
            arguments:
              parameters:
                - name: cpu_request
                  value: "{{tasks.map-compute.outputs.parameters.cpu_request}}"
                - name: cpu_limit
                  value: "{{tasks.map-compute.outputs.parameters.cpu_limit}}"
                - name: memory_request
                  value: "{{tasks.map-compute.outputs.parameters.memory_request}}"
                - name: memory_limit
                  value: "{{tasks.map-compute.outputs.parameters.memory_limit}}"

    # =========================================================================
    # Fan out: run each pipeline in parallel with computed resources
    # =========================================================================
    - name: run-pipeline-with-resources
      inputs:
        parameters:
          - name: cpu_request
          - name: cpu_limit
          - name: memory_request
          - name: memory_limit
      steps:
        - - name: run-pipeline
            template: single-pipeline
            arguments:
              parameters:
                - name: pipeline_name
                  value: "{{item}}"
                - name: cpu_request
                  value: "{{inputs.parameters.cpu_request}}"
                - name: cpu_limit
                  value: "{{inputs.parameters.cpu_limit}}"
                - name: memory_request
                  value: "{{inputs.parameters.memory_request}}"
                - name: memory_limit
                  value: "{{inputs.parameters.memory_limit}}"
            withParam: "{{workflow.parameters.pipelines}}"

    # =========================================================================
    # Single pipeline: clone, run, push, commit, tag - all in one container
    # =========================================================================
    - name: single-pipeline
      inputs:
        parameters:
          - name: pipeline_name
          - name: cpu_request
          - name: cpu_limit
          - name: memory_request
          - name: memory_limit
      outputs:
        parameters:
          - name: tag
            valueFrom:
              path: /tmp/outputs/tag.txt
          - name: changed
            valueFrom:
              path: /tmp/outputs/changed.txt
        artifacts:
          - name: pipeline-report
            path: /tmp/outputs/report.md
            archive:
              none: {}
      volumes:
        - name: git-secret
          secret:
            secretName: data-registry-repo
      podSpecPatch: |
        containers:
          - name: main
            resources:
              requests:
                cpu: "{{inputs.parameters.cpu_request}}"
                memory: "{{inputs.parameters.memory_request}}"
              limits:
                cpu: "{{inputs.parameters.cpu_limit}}"
                memory: "{{inputs.parameters.memory_limit}}"
      container:
        image: "{{workflow.parameters.image}}"
        command: [bash, -c]
        args:
          - |
            set -e

            PIPELINE="{{inputs.parameters.pipeline_name}}"
            FORCE="{{workflow.parameters.force}}"
            BUMP_TYPE="{{workflow.parameters.bump_type}}"
            IS_AUTOMATED="{{workflow.parameters.is_automated}}"

            # =================================================================
            # RESULT STATE
            # =================================================================
            mkdir -p /tmp/outputs
            echo "" > /tmp/outputs/tag.txt
            echo "false" > /tmp/outputs/changed.txt

            STATUS="unknown"
            NEW_TAG=""
            ERROR_MSG=""

            # =================================================================
            # BUSINESS LOGIC
            # =================================================================

            # Setup SSH
            mkdir -p ~/.ssh
            cat /mnt/secrets/sshPrivateKey > ~/.ssh/id_ed25519
            echo "" >> ~/.ssh/id_ed25519
            chmod 600 ~/.ssh/id_ed25519
            ssh-keyscan github.com >> ~/.ssh/known_hosts 2>/dev/null

            # Clone
            git clone git@github.com:OpenCloudHub/data-registry.git /tmp/repo
            cd /tmp/repo
            git config user.name "Argo Workflow"
            git config user.email "workflow@opencloudhub.org"

            # Hash before
            LOCK_FILE="pipelines/${PIPELINE}/dvc.lock"
            HASH_BEFORE="none"
            [ -f "$LOCK_FILE" ] && HASH_BEFORE=$(md5sum "$LOCK_FILE" | cut -d' ' -f1)

            # Run DVC
            FORCE_FLAG=""
            [ "$FORCE" = "true" ] && FORCE_FLAG="--force"
            dvc repro $FORCE_FLAG "pipelines/${PIPELINE}/dvc.yaml"

            # Push data
            dvc push

            # Check if changed
            HASH_AFTER="none"
            [ -f "$LOCK_FILE" ] && HASH_AFTER=$(md5sum "$LOCK_FILE" | cut -d' ' -f1)

            if [ "$HASH_BEFORE" = "$HASH_AFTER" ]; then
              STATUS="no_changes"
            else
              echo "true" > /tmp/outputs/changed.txt

              # Commit
              git add "pipelines/${PIPELINE}/"
              git add "data/${PIPELINE}/" 2>/dev/null || true
              git commit -m "chore(${PIPELINE}): update dvc.lock [skip ci]"

              # Push with retry
              PUSHED=false
              for attempt in 1 2 3; do
                if git push origin main; then
                  PUSHED=true
                  break
                fi
                git pull --rebase origin main
              done

              if [ "$PUSHED" = "false" ]; then
                STATUS="push_failed"
                ERROR_MSG="Could not push after 3 attempts"
              else
                # Create tag
                [ "$IS_AUTOMATED" = "true" ] && SUFFIX="-automated" || SUFFIX=""

                LATEST=$(git tag -l "${PIPELINE}-v*" --sort=-version:refname | head -n1 || echo "")
                if [ -z "$LATEST" ]; then
                  VERSION="1.0.0"
                else
                  CURRENT=$(echo "$LATEST" | sed "s/${PIPELINE}-v//" | sed 's/-automated//')
                  MAJOR=$(echo "$CURRENT" | cut -d. -f1)
                  MINOR=$(echo "$CURRENT" | cut -d. -f2)
                  PATCH=$(echo "$CURRENT" | cut -d. -f3)
                  case "$BUMP_TYPE" in
                    major) VERSION="$((MAJOR + 1)).0.0" ;;
                    minor) VERSION="${MAJOR}.$((MINOR + 1)).0" ;;
                    *) VERSION="${MAJOR}.${MINOR}.$((PATCH + 1))" ;;
                  esac
                fi

                NEW_TAG="${PIPELINE}-v${VERSION}${SUFFIX}"

                if git tag -l "$NEW_TAG" | grep -q .; then
                  STATUS="tag_exists"
                else
                  git tag -a "$NEW_TAG" -m "${PIPELINE} v${VERSION}"
                  git push origin "$NEW_TAG"
                  STATUS="success"
                fi

                echo "$NEW_TAG" > /tmp/outputs/tag.txt
              fi
            fi

            # =================================================================
            # REPORT GENERATION
            # =================================================================
            REPORT="/tmp/outputs/report.md"

            {
              echo ""
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo "ğŸ“¦ DATA PIPELINE"
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo ""
              echo "  Pipeline ...... $PIPELINE"
              echo "  Force ......... $FORCE"
              echo "  Bump Type ..... $BUMP_TYPE"
              echo "  Automated ..... $IS_AUTOMATED"
              echo ""
              echo "--------------------------------------------------"

              case "$STATUS" in
                no_changes)
                  echo "â„¹ï¸  NO CHANGES - Pipeline already up to date"
                  ;;
                push_failed)
                  echo "âŒ FAILED - $ERROR_MSG"
                  ;;
                tag_exists)
                  echo "â„¹ï¸  TAG EXISTS - $NEW_TAG"
                  ;;
                success)
                  echo "âœ… PIPELINE COMPLETE"
                  echo ""
                  echo "  Tag .......... $NEW_TAG"
                  echo "  Changed ...... true"
                  ;;
              esac

              echo "--------------------------------------------------"
              echo ""
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo ""
            } | tee "$REPORT"

            # Exit with error if failed
            [ "$STATUS" = "push_failed" ] && exit 1
            exit 0
        volumeMounts:
          - name: git-secret
            mountPath: /mnt/secrets
            readOnly: true
        envFrom:
          - secretRef:
              name: minio-tenant-secret
