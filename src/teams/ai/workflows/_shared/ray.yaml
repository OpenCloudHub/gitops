# =============================================================================
# Ray Job Templates
# =============================================================================
#
# Shared templates for submitting and monitoring Ray jobs.
# Reusable for training, embeddings, data processing, or any Ray workload.
# Provides log streaming from Ray job submitter pods to Argo UI.
#
# Templates:
#   submit-and-stream-rayjob - Main entry: submit + wait with log streaming (DAG)
#   submit-rayjob            - Create RayJob resource
#   stream-rayjob            - Stream logs and wait for completion
#
# Environment variables injected into Ray pods:
#   Platform (mlops-platform-env):  MLFLOW_TRACKING_URI, DVC_REPO_URL
#   Job-specific ({job}-env):       Custom env vars per job type
#   Secrets (minio-tenant-secret):  AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_ENDPOINT_URL
#   Tracking (inline):              ARGO_WORKFLOW_UID, DOCKER_IMAGE_TAG, DVC_DATA_VERSION, REPLICAS
#
# Known Limitation:
#   Ray job cleanup on workflow failure is handled by RayJob's TTL
#   (ttlSecondsAfterFinished: 300). For immediate cleanup, implement
#   an Argo exit handler that deletes the RayJob resource.
#
# =============================================================================

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ray-templates
  namespace: mlops
  annotations:
    workflows.argoproj.io/description: "Ray job submission and log streaming"
spec:
  templates:
    # =========================================================================
    # MAIN: Submit and wait with log streaming (DAG for proper output resolution)
    # =========================================================================
    - name: submit-and-stream-rayjob
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: base_configmap
          - name: job_configmap
          - name: job_secret
          - name: cpu
            default: "2"
          - name: memory
            default: "4Gi"
          - name: gpu
            default: "0"
          - name: replicas
            default: "1"
          - name: dvc_data_version
          - name: timeout
            default: "3600"

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              parameter: "{{tasks.submit-job.outputs.parameters.job_name}}"
          - name: job_status
            valueFrom:
              parameter: "{{tasks.stream-job.outputs.parameters.job_status}}"

      dag:
        tasks:
          - name: submit-job
            template: submit-rayjob
            arguments:
              parameters:
                - name: job_prefix
                  value: "{{inputs.parameters.job_prefix}}"
                - name: image
                  value: "{{inputs.parameters.image}}"
                - name: entrypoint
                  value: "{{inputs.parameters.entrypoint}}"
                - name: base_configmap
                  value: "{{inputs.parameters.base_configmap}}"
                - name: job_configmap
                  value: "{{inputs.parameters.job_configmap}}"
                - name: job_secret
                  value: "{{inputs.parameters.job_secret}}"
                - name: cpu
                  value: "{{inputs.parameters.cpu}}"
                - name: memory
                  value: "{{inputs.parameters.memory}}"
                - name: gpu
                  value: "{{inputs.parameters.gpu}}"
                - name: replicas
                  value: "{{inputs.parameters.replicas}}"
                - name: dvc_data_version
                  value: "{{inputs.parameters.dvc_data_version}}"

          - name: stream-job
            dependencies: [submit-job]
            template: stream-rayjob
            arguments:
              parameters:
                - name: job_name
                  value: "{{tasks.submit-job.outputs.parameters.job_name}}"
                - name: timeout
                  value: "{{inputs.parameters.timeout}}"

    # =========================================================================
    # SUBMIT: Create RayJob resource
    # =========================================================================
    - name: submit-rayjob
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: base_configmap
          - name: job_configmap
          - name: job_secret
          - name: cpu
          - name: memory
          - name: gpu
          - name: replicas
          - name: dvc_data_version

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              jsonPath: "{.metadata.name}"

      resource:
        action: create
        manifest: |
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            generateName: {{inputs.parameters.job_prefix}}-
            namespace: mlops
            labels:
              workflow: "{{workflow.name}}"
              workflow-uid: "{{workflow.uid}}"
          spec:
            entrypoint: "{{inputs.parameters.entrypoint}}"
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.51.0"
              headGroupSpec:
                rayStartParams:
                  dashboard-host: "0.0.0.0"
                  num-cpus: "0"
                template:
                  spec:
                    containers:
                      - name: ray-head
                        image: "{{inputs.parameters.image}}"
                        resources:
                          requests:
                            cpu: "500m"
                            memory: "4Gi"
                          limits:
                            cpu: "1"
                            memory: "6Gi"
                        envFrom:
                          - configMapRef:
                              name: "{{inputs.parameters.base_configmap}}"
                          - configMapRef:
                              name: "{{inputs.parameters.job_configmap}}"
                          - secretRef:
                              name: "{{inputs.parameters.job_secret}}"
                        env:
                          - name: ARGO_WORKFLOW_UID
                            value: "{{workflow.uid}}"
                          - name: ARGO_WORKFLOW_NAME
                            value: "{{workflow.name}}"
                          - name: DOCKER_IMAGE_TAG
                            value: "{{inputs.parameters.image}}"
                          - name: DVC_DATA_VERSION
                            value: "{{inputs.parameters.dvc_data_version}}"
                          - name: REPLICAS
                            value: "{{inputs.parameters.replicas}}"
              workerGroupSpecs:
                - groupName: workers
                  replicas: {{inputs.parameters.replicas}}
                  rayStartParams: {}
                  template:
                    spec:
                      containers:
                        - name: ray-worker
                          image: "{{inputs.parameters.image}}"
                          resources:
                            requests:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                            limits:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                              nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                          envFrom:
                            - configMapRef:
                                name: "{{inputs.parameters.base_configmap}}"
                            - configMapRef:
                                name: "{{inputs.parameters.job_configmap}}"
                            - secretRef:
                                name: "{{inputs.parameters.job_secret}}"
                          env:
                            - name: ARGO_WORKFLOW_UID
                              value: "{{workflow.uid}}"
                            - name: ARGO_WORKFLOW_NAME
                              value: "{{workflow.name}}"
                            - name: DOCKER_IMAGE_TAG
                              value: "{{inputs.parameters.image}}"
                            - name: DVC_DATA_VERSION
                              value: "{{inputs.parameters.dvc_data_version}}"
                            - name: REPLICAS
                              value: "{{inputs.parameters.replicas}}"

    # =========================================================================
    # WAIT: Stream logs from submitter pod while waiting for completion
    # =========================================================================
    - name: stream-rayjob
      inputs:
        parameters:
          - name: job_name
          - name: timeout
            default: "3600"
      outputs:
        parameters:
          - name: job_status
            valueFrom:
              path: /tmp/job_status.txt
        artifacts:
          - name: training-logs
            path: /tmp/training-logs.txt
            archive:
              none: {}
      script:
        image: bitnami/kubectl:latest
        command: [bash]
        source: |
          set -e

          JOB_NAME="{{inputs.parameters.job_name}}"
          TIMEOUT="{{inputs.parameters.timeout}}"

          echo "PENDING" > /tmp/job_status.txt

          {
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ğŸš€ RAY JOB"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
            echo "  Job ......... $JOB_NAME"
            echo "  Timeout ..... ${TIMEOUT}s"
            echo ""
          } | tee /tmp/training-logs.txt

          # Wait for submitter pod to exist and be running
          echo "â³ Waiting for submitter pod..." | tee -a /tmp/training-logs.txt
          ELAPSED=0
          SUBMITTER_POD=""
          while [ $ELAPSED -lt 120 ]; do
            SUBMITTER_POD=$(kubectl get pods -n mlops -o name 2>/dev/null | grep "^pod/${JOB_NAME}-" | grep -v -- "-head-" | grep -v -- "-worker" | head -1 | sed 's|pod/||' || echo "")

            if [ -n "$SUBMITTER_POD" ]; then
              POD_PHASE=$(kubectl get pod -n mlops "$SUBMITTER_POD" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")
              echo "  Found: $SUBMITTER_POD ($POD_PHASE)" | tee -a /tmp/training-logs.txt
              if [ "$POD_PHASE" = "Running" ] || [ "$POD_PHASE" = "Succeeded" ]; then
                break
              fi
            fi

            sleep 3
            ELAPSED=$((ELAPSED + 3))
          done

          if [ -z "$SUBMITTER_POD" ]; then
            {
              echo ""
              echo "--------------------------------------------------"
              echo "âŒ FAILED - Could not find submitter pod"
              echo "--------------------------------------------------"
              echo ""
              kubectl get pods -n mlops | grep "$JOB_NAME" || echo "(no pods found)"
              echo ""
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo ""
            } | tee -a /tmp/training-logs.txt
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi

          {
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ğŸ“ JOB LOGS"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
          } | tee -a /tmp/training-logs.txt

          # Stream logs - follows until pod completes
          kubectl logs -n mlops -f "$SUBMITTER_POD" 2>&1 | tee -a /tmp/training-logs.txt || true

          # Check final status
          FINAL_STATUS=$(kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo "UNKNOWN")

          {
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
          } >> /tmp/training-logs.txt

          if [ "$FINAL_STATUS" = "SUCCEEDED" ]; then
            {
              echo "--------------------------------------------------"
              echo "âœ… JOB COMPLETED SUCCESSFULLY"
              echo "--------------------------------------------------"
            } | tee -a /tmp/training-logs.txt
            echo "SUCCEEDED" > /tmp/job_status.txt
            echo "" | tee -a /tmp/training-logs.txt
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" | tee -a /tmp/training-logs.txt
            echo "" | tee -a /tmp/training-logs.txt
            exit 0
          else
            {
              echo "--------------------------------------------------"
              echo "âŒ JOB FAILED: $FINAL_STATUS"
              echo "--------------------------------------------------"
              echo ""
              kubectl describe rayjob -n mlops "$JOB_NAME" | tail -30
            } | tee -a /tmp/training-logs.txt
            echo "FAILED" > /tmp/job_status.txt
            echo "" | tee -a /tmp/training-logs.txt
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" | tee -a /tmp/training-logs.txt
            echo "" | tee -a /tmp/training-logs.txt
            exit 1
          fi
