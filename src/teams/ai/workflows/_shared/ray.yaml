# =============================================================================
# Ray Job Templates
# =============================================================================
#
# Shared templates for submitting and monitoring Ray jobs.
# Reusable for training, embeddings, data processing, or any Ray workload.
# Provides log streaming from Ray job submitter pods to Argo UI.
#
# Templates:
#   submit-and-stream-rayjob - Main entry: submit + wait with log streaming (DAG)
#   submit-rayjob            - Create RayJob resource, wait for job ID
#   stream-rayjob            - Stream logs via Ray API and wait for completion
#
# Environment variables injected into Ray pods:
#   Platform (mlops-platform-env):  MLFLOW_TRACKING_URI, DVC_REPO_URL
#   Job-specific ({job}-env):       Custom env vars per job type
#   Secrets (minio-tenant-secret):  AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_ENDPOINT_URL
#   Tracking (inline):              ARGO_WORKFLOW_UID, DOCKER_IMAGE_TAG, DVC_DATA_VERSION, REPLICAS
#
# Known Limitation:
#   Ray job cleanup on workflow failure is handled by RayJob's TTL
#   (ttlSecondsAfterFinished: 300). For immediate cleanup, implement
#   an Argo exit handler that deletes the RayJob resource.
#
# =============================================================================

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ray-templates
  namespace: mlops
  annotations:
    workflows.argoproj.io/description: "Ray job submission and log streaming"
spec:
  templates:
    # =========================================================================
    # MAIN: Submit and wait with log streaming (DAG for proper output resolution)
    # =========================================================================
    - name: submit-and-stream-rayjob
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: base_configmap
          - name: job_configmap
          - name: job_secret
          - name: cpu
            default: "2"
          - name: memory
            default: "4Gi"
          - name: gpu
            default: "0"
          - name: replicas
            default: "1"
          - name: dvc_data_version
          - name: timeout
            default: "3600"

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              parameter: "{{tasks.submit-job.outputs.parameters.job_name}}"
          - name: job_id
            valueFrom:
              parameter: "{{tasks.submit-job.outputs.parameters.job_id}}"
          - name: job_status
            valueFrom:
              parameter: "{{tasks.stream-job.outputs.parameters.job_status}}"

      dag:
        tasks:
          - name: submit-job
            template: submit-rayjob
            arguments:
              parameters:
                - name: job_prefix
                  value: "{{inputs.parameters.job_prefix}}"
                - name: image
                  value: "{{inputs.parameters.image}}"
                - name: entrypoint
                  value: "{{inputs.parameters.entrypoint}}"
                - name: base_configmap
                  value: "{{inputs.parameters.base_configmap}}"
                - name: job_configmap
                  value: "{{inputs.parameters.job_configmap}}"
                - name: job_secret
                  value: "{{inputs.parameters.job_secret}}"
                - name: cpu
                  value: "{{inputs.parameters.cpu}}"
                - name: memory
                  value: "{{inputs.parameters.memory}}"
                - name: gpu
                  value: "{{inputs.parameters.gpu}}"
                - name: replicas
                  value: "{{inputs.parameters.replicas}}"
                - name: dvc_data_version
                  value: "{{inputs.parameters.dvc_data_version}}"

          - name: stream-job
            dependencies: [submit-job]
            template: stream-rayjob
            arguments:
              parameters:
                - name: job_name
                  value: "{{tasks.submit-job.outputs.parameters.job_name}}"
                - name: job_id
                  value: "{{tasks.submit-job.outputs.parameters.job_id}}"
                - name: timeout
                  value: "{{inputs.parameters.timeout}}"

    # =========================================================================
    # SUBMIT: Create RayJob resource and wait for job ID
    # =========================================================================
    - name: submit-rayjob
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: base_configmap
          - name: job_configmap
          - name: job_secret
          - name: cpu
          - name: memory
          - name: gpu
          - name: replicas
          - name: dvc_data_version

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              jsonPath: "{.metadata.name}"
          - name: job_id
            valueFrom:
              jsonPath: "{.status.jobId}"

      resource:
        action: create
        successCondition: status.jobStatus in (PENDING, RUNNING)
        failureCondition: status.jobDeploymentStatus == Failed
        manifest: |
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            generateName: {{inputs.parameters.job_prefix}}-
            namespace: mlops
            labels:
              workflow: "{{workflow.name}}"
              workflow-uid: "{{workflow.uid}}"
          spec:
            entrypoint: "{{inputs.parameters.entrypoint}}"
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.51.0"
              headGroupSpec:
                rayStartParams:
                  dashboard-host: "0.0.0.0"
                  num-cpus: "0"
                template:
                  spec:
                    containers:
                      - name: ray-head
                        image: "{{inputs.parameters.image}}"
                        resources:
                          requests:
                            cpu: "500m"
                            memory: "4Gi"
                          limits:
                            cpu: "1"
                            memory: "6Gi"
                        envFrom:
                          - configMapRef:
                              name: "{{inputs.parameters.base_configmap}}"
                          - configMapRef:
                              name: "{{inputs.parameters.job_configmap}}"
                          - secretRef:
                              name: "{{inputs.parameters.job_secret}}"
                        env:
                          - name: ARGO_WORKFLOW_UID
                            value: "{{workflow.uid}}"
                          - name: ARGO_WORKFLOW_NAME
                            value: "{{workflow.name}}"
                          - name: DOCKER_IMAGE_TAG
                            value: "{{inputs.parameters.image}}"
                          - name: DVC_DATA_VERSION
                            value: "{{inputs.parameters.dvc_data_version}}"
                          - name: REPLICAS
                            value: "{{inputs.parameters.replicas}}"
              workerGroupSpecs:
                - groupName: workers
                  replicas: {{inputs.parameters.replicas}}
                  rayStartParams: {}
                  template:
                    spec:
                      containers:
                        - name: ray-worker
                          image: "{{inputs.parameters.image}}"
                          resources:
                            requests:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                            limits:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                              nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                          envFrom:
                            - configMapRef:
                                name: "{{inputs.parameters.base_configmap}}"
                            - configMapRef:
                                name: "{{inputs.parameters.job_configmap}}"
                            - secretRef:
                                name: "{{inputs.parameters.job_secret}}"
                          env:
                            - name: ARGO_WORKFLOW_UID
                              value: "{{workflow.uid}}"
                            - name: ARGO_WORKFLOW_NAME
                              value: "{{workflow.name}}"
                            - name: DOCKER_IMAGE_TAG
                              value: "{{inputs.parameters.image}}"
                            - name: DVC_DATA_VERSION
                              value: "{{inputs.parameters.dvc_data_version}}"
                            - name: REPLICAS
                              value: "{{inputs.parameters.replicas}}"

    # =========================================================================
    # STREAM: Stream logs via Ray API while waiting for completion
    # =========================================================================
    - name: stream-rayjob
      inputs:
        parameters:
          - name: job_name
          - name: job_id
          - name: timeout
            default: "3600"
      outputs:
        parameters:
          - name: job_status
            valueFrom:
              path: /tmp/job_status.txt
        artifacts:
          - name: training-logs
            path: /tmp/training-logs.txt
            archive:
              none: {}
      script:
        image: rayproject/ray:2.51.0-py312
        command: [bash]
        source: |
          set -e

          JOB_NAME="{{inputs.parameters.job_name}}"
          JOB_ID="{{inputs.parameters.job_id}}"
          TIMEOUT="{{inputs.parameters.timeout}}"
          HEAD_SVC="${JOB_NAME}-head-svc.mlops.svc.cluster.local:8265"

          echo "PENDING" > /tmp/job_status.txt

          {
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ðŸš€ RAY JOB"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
            echo "  Resource .... $JOB_NAME"
            echo "  Job ID ...... $JOB_ID"
            echo "  Head SVC .... $HEAD_SVC"
            echo "  Timeout ..... ${TIMEOUT}s"
            echo ""
          } | tee /tmp/training-logs.txt

          # Wait for Ray head service to be ready
          echo "â³ Waiting for Ray cluster..." | tee -a /tmp/training-logs.txt
          ELAPSED=0
          while [ $ELAPSED -lt 180 ]; do
            if ray job list --address "http://$HEAD_SVC" &>/dev/null; then
              echo "  âœ“ Ray cluster ready" | tee -a /tmp/training-logs.txt
              break
            fi
            sleep 5
            ELAPSED=$((ELAPSED + 5))
          done

          if [ $ELAPSED -ge 180 ]; then
            echo "âŒ Timeout waiting for Ray cluster" | tee -a /tmp/training-logs.txt
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi

          {
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ðŸ“ JOB LOGS"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
          } | tee -a /tmp/training-logs.txt

          # Stream logs via Ray API using actual job ID
          ray job logs --address "http://$HEAD_SVC" "$JOB_ID" --follow 2>&1 | tee -a /tmp/training-logs.txt || true

          # Check final status via Ray API
          FINAL_STATUS=$(ray job status --address "http://$HEAD_SVC" "$JOB_ID" 2>/dev/null | grep -oP 'Status: \K\w+' || echo "UNKNOWN")

          if [ "$FINAL_STATUS" = "SUCCEEDED" ]; then
            {
              echo ""
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo "âœ… JOB COMPLETED SUCCESSFULLY"
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo ""
            } | tee -a /tmp/training-logs.txt
            echo "SUCCEEDED" > /tmp/job_status.txt
            exit 0
          else
            {
              echo ""
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo "âŒ JOB FAILED: $FINAL_STATUS"
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo ""
            } | tee -a /tmp/training-logs.txt
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi
