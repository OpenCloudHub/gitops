apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: mlops-pipeline
  namespace: ai
spec:
  serviceAccountName: workflow-executor

  arguments:
    parameters:
    - name: repo_name
      description: "Name of the GitHub repo to build the serving image from"
    - name: model_name
      description: "Model name (e.g., wine-classifier)"
    - name: experiment_name
      description: "MLflow experiment name"
    - name: compute_type
      enum: [cpu-small, cpu-medium, cpu-large, gpu-small, gpu-medium, gpu-large]
      description: "Compute configuration"
    - name: approval_mode
      value: "manual"
      enum: [manual, automatic]
    - name: comparison_metric
      value: "accuracy"
      description: "Metric to compare"
    - name: higher_is_better
      value: "true"
      description: "Whether higher metric values are better (true/false)"
    - name: comparison_threshold
      value: "0.05"
      description: "Minimum improvement threshold"
    - name: training_image
      description: "Container image with training code"
    - name: training_entrypoint
      value: "python src/training/train.py"
    - name: training_args
      value: ""
    - name: mlflow_tracking_uri
      value: "http://mlflow.ai.svc.cluster.local:80"
    - name: docker_registry
      value: "docker.io/opencloudhuborg"

  entrypoint: main

  templates:
  - name: main
    steps:
    # Phase 1: Map compute config
    - - name: map-compute
        template: map-compute-config
        arguments:
          parameters:
          - name: compute_type
            value: "{{workflow.parameters.compute_type}}"

    # Phase 2: Submit Ray job
    - - name: submit-training
        template: submit-ray-job
        arguments:
          parameters:
          - name: model_name
            value: "{{workflow.parameters.model_name}}"
          - name: experiment_name
            value: "{{workflow.parameters.experiment_name}}"
          - name: training_image
            value: "{{workflow.parameters.training_image}}"
          - name: training_entrypoint
            value: "{{workflow.parameters.training_entrypoint}}"
          - name: training_args
            value: "{{workflow.parameters.training_args}}"
          - name: cpu
            value: "{{steps.map-compute.outputs.parameters.cpu}}"
          - name: memory
            value: "{{steps.map-compute.outputs.parameters.memory}}"
          - name: replicas
            value: "{{steps.map-compute.outputs.parameters.replicas}}"
          - name: gpu
            value: "{{steps.map-compute.outputs.parameters.gpu}}"
          - name: mlflow_tracking_uri
            value: "{{workflow.parameters.mlflow_tracking_uri}}"

    # Phase 3: Compare and promote to staging
    - - name: compare-promote
        template: compare-and-promote
        arguments:
          parameters:
          - name: model_name
            value: "{{workflow.parameters.model_name}}"
          - name: metric
            value: "{{workflow.parameters.comparison_metric}}"
          - name: higher_is_better
            value: "{{workflow.parameters.higher_is_better}}"
          - name: threshold
            value: "{{workflow.parameters.comparison_threshold}}"
          - name: mlflow_tracking_uri
            value: "{{workflow.parameters.mlflow_tracking_uri}}"

    # Phase 4: Build staging image
    - - name: build-staging
        template: build-staging-image
        arguments:
          parameters:
          - name: model_name
            value: "{{workflow.parameters.model_name}}"
          - name: staging_version
            value: "{{steps.compare-promote.outputs.parameters.staging_version}}"
          - name: registry
            value: "{{workflow.parameters.docker_registry}}"
          - name: repo_name
            value: "{{workflow.parameters.repo_name}}"
          - name: mlflow_tracking_uri
            value: "{{workflow.parameters.mlflow_tracking_uri}}"

    # Phase 5: Test staging
    - - name: test-staging
        template: test-staging
        arguments:
          parameters:
          - name: image_tag
            value: "{{steps.build-staging.outputs.parameters.staging_image_tag}}"

    # Phase 6: Approval gate with timeout
    - - name: approval
        template: approval-gate
        when: "{{workflow.parameters.approval_mode}} == manual"

    # Phase 7: Check approval and fail if not approved
    - - name: check-approval
        template: check-approval-status
        arguments:
          parameters:
          - name: approval_decision
            value: "{{steps.approval.outputs.parameters.approve}}"
        when: "{{workflow.parameters.approval_mode}} == manual"

    # Phase 8: Promote to production (only runs if approved OR automatic)
    - - name: promote-production
        template: promote-to-production
        arguments:
          parameters:
          - name: model_name
            value: "{{workflow.parameters.model_name}}"
          - name: staging_version
            value: "{{steps.compare-promote.outputs.parameters.staging_version}}"
          - name: mlflow_tracking_uri
            value: "{{workflow.parameters.mlflow_tracking_uri}}"
        when: "{{workflow.parameters.approval_mode}} == automatic || ({{workflow.parameters.approval_mode}} == manual && '{{steps.approval.outputs.parameters.approve}}' == 'YES')"

    # Phase 9: Retag image (only runs if we promoted)
    - - name: retag-production
        template: retag-image
        arguments:
          parameters:
          - name: staging_image
            value: "{{steps.build-staging.outputs.parameters.staging_image_tag}}"
          - name: registry
            value: "{{workflow.parameters.docker_registry}}"
        when: "{{workflow.parameters.approval_mode}} == automatic || ({{workflow.parameters.approval_mode}} == manual && '{{steps.approval.outputs.parameters.approve}}' == 'YES')"

  # ========================================================================
  # TEMPLATE DEFINITIONS
  # ========================================================================

  # Map compute type to resources
  - name: map-compute-config
    inputs:
      parameters:
      - name: compute_type
    outputs:
      parameters:
      - name: cpu
        valueFrom:
          path: /tmp/cpu.txt
      - name: memory
        valueFrom:
          path: /tmp/memory.txt
      - name: replicas
        valueFrom:
          path: /tmp/replicas.txt
      - name: gpu
        valueFrom:
          path: /tmp/gpu.txt
    script:
      image: alpine:latest
      command: [sh]
      source: |
        #!/bin/sh
        set -e

        case "{{inputs.parameters.compute_type}}" in
          cpu-small)
            echo "2" > /tmp/cpu.txt
            echo "4Gi" > /tmp/memory.txt
            echo "1" > /tmp/replicas.txt
            echo "0" > /tmp/gpu.txt
            ;;
          cpu-medium)
            echo "4" > /tmp/cpu.txt
            echo "8Gi" > /tmp/memory.txt
            echo "1" > /tmp/replicas.txt
            echo "0" > /tmp/gpu.txt
            ;;
          cpu-large)
            echo "8" > /tmp/cpu.txt
            echo "16Gi" > /tmp/memory.txt
            echo "2" > /tmp/replicas.txt
            echo "0" > /tmp/gpu.txt
            ;;
          gpu-small)
            echo "4" > /tmp/cpu.txt
            echo "16Gi" > /tmp/memory.txt
            echo "1" > /tmp/replicas.txt
            echo "1" > /tmp/gpu.txt
            ;;
          gpu-medium)
            echo "8" > /tmp/cpu.txt
            echo "32Gi" > /tmp/memory.txt
            echo "1" > /tmp/replicas.txt
            echo "2" > /tmp/gpu.txt
            ;;
          gpu-large)
            echo "16" > /tmp/cpu.txt
            echo "64Gi" > /tmp/memory.txt
            echo "1" > /tmp/replicas.txt
            echo "4" > /tmp/gpu.txt
            ;;
          *)
            echo "Unknown compute type: {{inputs.parameters.compute_type}}"
            exit 1
            ;;
        esac

        echo "‚úÖ Mapped {{inputs.parameters.compute_type}}"

  # Submit RayJob
  - name: submit-ray-job
    inputs:
      parameters:
      - name: model_name
      - name: experiment_name
      - name: training_image
      - name: training_entrypoint
      - name: training_args
      - name: cpu
      - name: memory
      - name: replicas
      - name: gpu
      - name: mlflow_tracking_uri
    outputs:
      parameters:
      - name: job-name
        valueFrom:
          path: /tmp/job-name.txt
    script:
      image: bitnami/kubectl:latest
      command: [sh]
      source: |
        set -e

        GPU="{{inputs.parameters.gpu}}"

        # Build GPU resources block if needed
        GPU_RESOURCES=""
        GPU_NODE_SELECTOR=""
        if [ "$GPU" != "0" ]; then
          GPU_RESOURCES="nvidia.com/gpu: \"$GPU\""
          GPU_NODE_SELECTOR="nodeSelector:
          node.opencloudhub.org/gpu: \"true\""
        fi

        # Create unique label for this workflow run (no $$ - use seconds + random)
        RUN_LABEL="wf-$(date +%s)-${RANDOM}"

        echo "Creating RayJob with label: workflow-run=${RUN_LABEL}"

        cat <<EOF | kubectl create -f -
        apiVersion: ray.io/v1
        kind: RayJob
        metadata:
          generateName: {{inputs.parameters.model_name}}-training-
          namespace: ai
          labels:
            workflow-run: "${RUN_LABEL}"
            model: "{{inputs.parameters.model_name}}"
        spec:
          entrypoint: {{inputs.parameters.training_entrypoint}} {{inputs.parameters.training_args}}
          shutdownAfterJobFinishes: true
          ttlSecondsAfterFinished: 300
          rayClusterSpec:
            rayVersion: "2.48.0"
            headGroupSpec:
              serviceType: ClusterIP
              template:
                spec:
                  ${GPU_NODE_SELECTOR}
                  containers:
                  - name: ray-head
                    image: {{inputs.parameters.training_image}}
                    resources:
                      requests:
                        cpu: "{{inputs.parameters.cpu}}"
                        memory: "{{inputs.parameters.memory}}"
                      limits:
                        cpu: "{{inputs.parameters.cpu}}"
                        memory: "{{inputs.parameters.memory}}"
                        ${GPU_RESOURCES}
                    env:
                    - name: MLFLOW_TRACKING_URI
                      value: {{inputs.parameters.mlflow_tracking_uri}}
                    - name: MLFLOW_EXPERIMENT_NAME
                      value: {{inputs.parameters.experiment_name}}
                    - name: MLFLOW_REGISTERED_MODEL_NAME
                      value: "ci.{{inputs.parameters.model_name}}"
            workerGroupSpecs:
            - replicas: {{inputs.parameters.replicas}}
              groupName: worker
              template:
                spec:
                  ${GPU_NODE_SELECTOR}
                  containers:
                  - name: ray-worker
                    image: {{inputs.parameters.training_image}}
                    resources:
                      requests:
                        cpu: "{{inputs.parameters.cpu}}"
                        memory: "{{inputs.parameters.memory}}"
                      limits:
                        cpu: "{{inputs.parameters.cpu}}"
                        memory: "{{inputs.parameters.memory}}"
                        ${GPU_RESOURCES}
                    env:
                      - name: MLFLOW_TRACKING_URI
                        value: "{{inputs.parameters.mlflow_tracking_uri}}"
                      - name: MLFLOW_EXPERIMENT_NAME
                        value: "{{inputs.parameters.experiment_name}}"
                      - name: MLFLOW_REGISTERED_MODEL_NAME
                        value: "ci.{{inputs.parameters.model_name}}"
        EOF

        # ========================================
        # Verify RayJob created
        # ========================================
        echo "‚è≥ Waiting for RayJob..."
        sleep 3

        JOB_NAME=$(kubectl get rayjobs -n ai -l workflow-run="${RUN_LABEL}" -o jsonpath='{.items[0].metadata.name}')

        if [ -z "$JOB_NAME" ]; then
          echo "‚ùå Failed to get RayJob"
          exit 1
        fi

        echo "‚úÖ RayJob: $JOB_NAME"
        echo "$JOB_NAME" > /tmp/job-name.txt

        # ========================================
        # Wait for job submitter pod
        # ========================================
        echo "‚è≥ Waiting for job submitter pod..."

        MAX_WAIT=60
        ELAPSED=0
        SUBMITTER_POD=""

        while [ $ELAPSED -lt $MAX_WAIT ]; do
          SUBMITTER_POD=$(kubectl get pods -n ai -l ray.io/is-ray-node!=yes | grep ${JOB_NAME} | awk '{print $1}' | head -n1)

          if [ -n "$SUBMITTER_POD" ]; then
            break
          fi

          sleep 5
          ELAPSED=$((ELAPSED + 5))
        done

        if [ -z "$SUBMITTER_POD" ]; then
          echo "‚ùå Job submitter pod not found after ${MAX_WAIT}s"
          exit 1
        fi

        echo "‚úÖ Submitter pod: $SUBMITTER_POD"
        echo ""
        echo "üîç Streaming training logs..."
        echo "================================"

        # Stream logs from job submitter
        kubectl logs -n ai $SUBMITTER_POD -f &
        LOG_PID=$!

        # ========================================
        # Wait for completion
        # ========================================
        while true; do
          STATUS=$(kubectl get rayjob -n ai $JOB_NAME -o jsonpath='{.status.jobStatus}')

          case "$STATUS" in
            "SUCCEEDED")
              sleep 3
              kill $LOG_PID 2>/dev/null || true
              echo ""
              echo "‚úÖ Training complete!"
              exit 0
              ;;
            "FAILED"|"STOPPED")
              kill $LOG_PID 2>/dev/null || true
              echo ""
              echo "‚ùå Training failed: $STATUS"
              exit 1
              ;;
          esac

          sleep 10
        done

  # Compare and promote to staging
  - name: compare-and-promote
    inputs:
      parameters:
      - name: model_name
      - name: metric
      - name: higher_is_better
      - name: threshold
      - name: mlflow_tracking_uri
    outputs:
      parameters:
      - name: ci_version
        valueFrom:
          path: /tmp/ci_version.txt
      - name: staging_version
        valueFrom:
          path: /tmp/staging_version.txt
    script:
      image: ghcr.io/mlflow/mlflow:v2.18.0
      command: [python]
      source: |
        from mlflow import MlflowClient
        import sys

        client = MlflowClient("{{inputs.parameters.mlflow_tracking_uri}}")
        model_name = "{{inputs.parameters.model_name}}"
        metric_name = "{{inputs.parameters.metric}}"
        higher_is_better = "{{inputs.parameters.higher_is_better}}" == "true"
        threshold = float("{{inputs.parameters.threshold}}")

        print(f"üîç Comparing {model_name}")
        print(f"   Metric: {metric_name} ({'higher' if higher_is_better else 'lower'} is better)")
        print(f"   Threshold: {threshold}")

        # Get latest CI version
        print(f"\nüìä Getting latest CI model...")
        ci_versions = client.search_model_versions(f"name='ci.{model_name}'")
        if not ci_versions:
            print(f"‚ùå No CI versions found for ci.{model_name}")
            sys.exit(1)

        latest_ci = sorted(ci_versions, key=lambda x: x.creation_timestamp, reverse=True)[0]
        ci_version = latest_ci.version
        print(f"   Latest CI: v{ci_version}")

        # Get CI metrics
        ci_run = client.get_run(latest_ci.run_id)
        if metric_name not in ci_run.data.metrics:
            print(f"‚ùå Metric '{metric_name}' not found in CI model")
            print(f"   Available: {list(ci_run.data.metrics.keys())}")
            sys.exit(1)

        ci_value = ci_run.data.metrics[metric_name]
        print(f"   CI {metric_name}: {ci_value}")

        # Try to get champion
        print(f"\nüèÜ Looking for champion...")
        should_promote = False
        try:
            champion = client.get_model_version_by_alias(f"prod.{model_name}", "champion")
            print(f"   Found champion: v{champion.version}")

            champ_run = client.get_run(champion.run_id)
            if metric_name not in champ_run.data.metrics:
                print(f"   Champion missing {metric_name}, promoting CI")
                should_promote = True
            else:
                champ_value = champ_run.data.metrics[metric_name]
                print(f"   Champion {metric_name}: {champ_value}")

                # Compare
                if higher_is_better:
                    improvement = ci_value - champ_value
                else:
                    improvement = champ_value - ci_value

                print(f"   Improvement: {improvement:.6f}")

                if improvement >= threshold:
                    print(f"‚úÖ CI is better! ({improvement:.6f} >= {threshold:.6f})")
                    should_promote = True
                else:
                    print(f"‚ùå Not enough improvement ({improvement:.6f} < {threshold:.6f})")
                    sys.exit(1)
        except Exception as e:
            print(f"   No champion found: {e}")
            print("   Promoting first model!")
            should_promote = True

        if not should_promote:
            # TODO could send notification here or like tag the staging image or something
            sys.exit(1)

        # Copy to staging
        print(f"\nüì¶ Copying ci.{model_name}/v{ci_version} ‚Üí staging.{model_name}")
        staging_mv = client.copy_model_version(
            f"models:/ci.{model_name}/{ci_version}",
            f"staging.{model_name}"
        )

        print(f"‚úÖ Created staging.{model_name}/v{staging_mv.version}")

        # Write outputs
        with open("/tmp/ci_version.txt", "w") as f:
            f.write(ci_version)
        with open("/tmp/staging_version.txt", "w") as f:
            f.write(staging_mv.version)

        print("‚úÖ Comparison complete!")

  # Build staging image
  - name: build-staging-image
    inputs:
      parameters:
      - name: model_name
      - name: staging_version
      - name: registry
      - name: repo_name
      - name: mlflow_tracking_uri
    outputs:
      parameters:
      - name: staging_image_tag
        valueFrom:
          path: /tmp/image_tag.txt
      - name: git_sha
        valueFrom:
          path: /tmp/git_sha.txt
    volumes:
    - name: docker-config
      secret:
        secretName: dockerhub-secret
        items:
        - key: .dockerconfigjson
          path: config.json
    - name: work
      emptyDir: {}
    container:
      image: moby/buildkit:v0.9.3-rootless
      readinessProbe:
        exec:
          command: [sh, -c, "buildctl debug workers"]
      volumeMounts:
      - name: docker-config
        mountPath: /.docker
        readOnly: true
      - name: work
        mountPath: /work
      workingDir: /work
      env:
      - name: BUILDKITD_FLAGS
        value: --oci-worker-no-process-sandbox
      - name: DOCKER_CONFIG
        value: /.docker
      command: [sh, -c]
      args:
      - |
        set -e

        # Clone repo
        git clone https://github.com/opencloudhub/{{inputs.parameters.repo_name}}.git .
        GIT_SHA=$(git rev-parse --short HEAD)

        IMAGE_TAG="{{inputs.parameters.registry}}/{{inputs.parameters.model_name}}-serving:model-v{{inputs.parameters.staging_version}}-${GIT_SHA}-staging"

        echo "$IMAGE_TAG" > /tmp/image_tag.txt
        echo "$GIT_SHA" > /tmp/git_sha.txt

        echo "üê≥ Building serving image: $IMAGE_TAG"

        buildctl-daemonless.sh build \
          --frontend dockerfile.v0 \
          --local context=. \
          --local dockerfile=. \
          --opt target=serving \
          --opt build-arg:MLFLOW_TRACKING_URI={{inputs.parameters.mlflow_tracking_uri}} \
          --opt build-arg:MODEL_NAME=staging.{{inputs.parameters.model_name}} \
          --opt build-arg:MODEL_VERSION={{inputs.parameters.staging_version}} \
          --output type=image,name=$IMAGE_TAG,push=true

        echo "‚úÖ Serving image built and pushed: $IMAGE_TAG"


  # Test staging
  - name: test-staging
    inputs:
      parameters:
      - name: image_tag
    script:
      image: alpine:latest
      command: [sh]
      source: |
        echo "üß™ Testing: {{inputs.parameters.image_tag}}"
        echo "‚úÖ Tests passed (dummy for POC)"

  # Template for approval gate
  - name: approval-gate
    suspend:
      duration: "48h"
    inputs:
      parameters:
      - name: approve
        description: "Approve promotion to production?"
        default: "NO"
        enum:
        - "YES"
        - "NO"
    outputs:
      parameters:
      - name: approve
        valueFrom:
          supplied: {}

  - name: check-approval-status
    inputs:
      parameters:
      - name: approval_decision
    script:
      image: alpine:latest
      command: [sh]
      source: |
        echo "================================"
        echo "Checking approval decision..."
        echo "Decision: {{inputs.parameters.approval_decision}}"
        echo "================================"

        if [ "{{inputs.parameters.approval_decision}}" != "YES" ]; then
          echo ""
          echo "‚ùå WORKFLOW FAILED: Approval denied or timed out"
          echo ""
          echo "The staging model was not approved for production."
          echo "Possible reasons:"
          echo "  - Manual rejection (user selected NO)"
          echo "  - Timeout (no response within 48 hours)"
          echo ""
          echo "The workflow will now fail."
          echo "================================"
          exit 1
        fi

        echo ""
        echo "‚úÖ Approval granted - proceeding to production"
        echo "================================"
        exit 0

  # Promote to production
  - name: promote-to-production
    inputs:
      parameters:
      - name: model_name
      - name: staging_version
      - name: mlflow_tracking_uri
    outputs:
      parameters:
      - name: prod_version
        valueFrom:
          path: /tmp/prod_version.txt
    script:
      image: ghcr.io/mlflow/mlflow:v2.18.0
      command: [python]
      source: |
        from mlflow import MlflowClient

        client = MlflowClient("{{inputs.parameters.mlflow_tracking_uri}}")
        model_name = "{{inputs.parameters.model_name}}"
        staging_version = "{{inputs.parameters.staging_version}}"

        print(f"üöÄ Promoting to production: {model_name}")

        # Copy staging ‚Üí prod
        print(f"üì¶ Copying staging.{model_name}/v{staging_version} ‚Üí prod.{model_name}")
        prod_mv = client.copy_model_version(
            f"models:/staging.{model_name}/{staging_version}",
            f"prod.{model_name}"
        )

        print(f"‚úÖ Created prod.{model_name}/v{prod_mv.version}")

        # Update aliases
        try:
            old_champ = client.get_model_version_by_alias(f"prod.{model_name}", "champion")
            print(f"   Moving old champion v{old_champ.version} ‚Üí @previous")
            client.set_registered_model_alias(f"prod.{model_name}", "previous", old_champ.version)
        except:
            print("   No previous champion to archive")

        # Set new champion
        client.set_registered_model_alias(f"prod.{model_name}", "champion", prod_mv.version)
        print(f"‚úÖ Set prod.{model_name}@champion ‚Üí v{prod_mv.version}")

        with open("/tmp/prod_version.txt", "w") as f:
            f.write(prod_mv.version)

        print("‚úÖ Production promotion complete!")

  # Retag image to production
  - name: retag-image
    inputs:
      parameters:
      - name: staging_image
      - name: registry
    outputs:
      parameters:
      - name: prod_image
        valueFrom:
          path: /tmp/prod_image.txt
      - name: prod_image_latest
        valueFrom:
          path: /tmp/prod_image_latest.txt
    volumes:
    - name: docker-config
      secret:
        secretName: dockerhub-secret
    container:
      image: gcr.io/go-containerregistry/crane:latest
      volumeMounts:
      - name: docker-config
        mountPath: /.docker
        readOnly: true
      env:
      - name: DOCKER_CONFIG
        value: /.docker
      command: [sh]
      source: |
        set -e

        STAGING="{{inputs.parameters.staging_image}}"
        # Remove -staging, add -prod
        BASE="${STAGING%-staging}"
        PROD_VERSIONED="${BASE}-prod"

        # Extract model name for latest tag
        # From: opencloudhuborg/wine-classifier-serving:model-v1-abc123-staging
        # To:   opencloudhuborg/wine-classifier-serving:prod-latest
        REGISTRY_AND_IMAGE="${STAGING%:*}"  # opencloudhuborg/wine-classifier-serving
        PROD_LATEST="${REGISTRY_AND_IMAGE}:prod-latest"

        echo "üè∑Ô∏è  Retagging image with multiple tags:"
        echo "   From:     $STAGING"
        echo "   To (ver): $PROD_VERSIONED"
        echo "   To (lat): $PROD_LATEST"

        # Copy to versioned prod tag
        crane copy "$STAGING" "$PROD_VERSIONED"

        # Also tag as prod-latest
        crane copy "$STAGING" "$PROD_LATEST"

        echo "$PROD_VERSIONED" > /tmp/prod_image.txt
        echo "$PROD_LATEST" > /tmp/prod_image_latest.txt

        echo "‚úÖ Production images ready!"
        echo "   Versioned: $PROD_VERSIONED"
        echo "   Latest:    $PROD_LATEST"
