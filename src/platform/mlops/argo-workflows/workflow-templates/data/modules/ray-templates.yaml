apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ray-templates
  namespace: mlops
  annotations:
    description: "Reusable templates for Ray job submission and monitoring"
spec:
  templates:
    # ==========================================================================
    # CREATE RAYJOB USING ARGO RESOURCE TEMPLATE
    # ==========================================================================
    - name: create-rayjob-resource
      inputs:
        parameters:
          - name: run_label
          - name: data_version
          - name: force
          - name: image
          - name: workflow_uid
          - name: cpu_request
          - name: cpu_limit
          - name: memory_request
          - name: memory_limit
          - name: replicas
      outputs:
        parameters:
          - name: job_name
            valueFrom:
              jsonPath: "{.metadata.name}"
      resource:
        action: create
        successCondition: status.jobDeploymentStatus in (Running, Complete)
        failureCondition: status.jobDeploymentStatus == Failed
        manifest: |
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            generateName: embeddings-
            namespace: mlops
            labels:
              run: "{{inputs.parameters.run_label}}"
              pipeline: embeddings
          spec:
            entrypoint: "python /workspace/project/pipelines/opencloudhub-readmes-embeddings/run_pipeline.py"
            submissionMode: HTTPMode
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.51.0"
              headGroupSpec:
                serviceType: ClusterIP
                template:
                  spec:
                    containers:
                    - name: ray-head
                      image: "{{inputs.parameters.image}}"
                      imagePullPolicy: Always
                      resources:
                        requests:
                          cpu: "{{inputs.parameters.cpu_request}}"
                          memory: "{{inputs.parameters.memory_request}}"
                        limits:
                          cpu: "{{inputs.parameters.cpu_limit}}"
                          memory: "{{inputs.parameters.memory_limit}}"
                      env:
                      - name: DVC_DATA_VERSION
                        value: "{{inputs.parameters.data_version}}"
                      - name: DOCKER_IMAGE
                        value: "{{inputs.parameters.image}}"
                      - name: ARGO_WORKFLOW_UID
                        value: "{{workflow.uid}}"
                      - name: FORCE_RUN
                        value: "{{inputs.parameters.force}}"
                      - name: DVC_REPO
                        value: "https://github.com/OpenCloudHub/data-registry"
                      - name: AWS_ACCESS_KEY_ID
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: accesskey
                      - name: AWS_SECRET_ACCESS_KEY
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: secretkey
                      - name: AWS_ENDPOINT_URL
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: endpoint-url
                      - name: PGVECTOR_HOST
                        value: "demo-app-db-cluster-rw.storage.svc.cluster.local"
                      - name: POSTGRES_DEMO_APP_DB_PASSWORD
                        valueFrom:
                          secretKeyRef:
                            name: demo-app-db-user
                            key: password
              workerGroupSpecs:
              - replicas: {{inputs.parameters.replicas}}
                groupName: worker
                template:
                  spec:
                    containers:
                    - name: ray-worker
                      image: "{{inputs.parameters.image}}"
                      imagePullPolicy: Always
                      resources:
                        requests:
                          cpu: "{{inputs.parameters.cpu_request}}"
                          memory: "{{inputs.parameters.memory_request}}"
                        limits:
                          cpu: "{{inputs.parameters.cpu_limit}}"
                          memory: "{{inputs.parameters.memory_limit}}"
                      env:
                      - name: DVC_DATA_VERSION
                        value: "{{inputs.parameters.data_version}}"
                      - name: DOCKER_IMAGE
                        value: "{{inputs.parameters.image}}"
                      - name: ARGO_WORKFLOW_UID
                        value: "{{workflow.uid}}"
                      - name: FORCE_RUN
                        value: "{{inputs.parameters.force}}"
                      - name: DVC_REPO
                        value: "https://github.com/OpenCloudHub/data-registry"
                      - name: AWS_ACCESS_KEY_ID
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: accesskey
                      - name: AWS_SECRET_ACCESS_KEY
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: secretkey
                      - name: AWS_ENDPOINT_URL
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: endpoint-url
                      - name: PGVECTOR_HOST
                        value: "demo-app-db-cluster-rw.storage.svc.cluster.local"
                      - name: POSTGRES_DEMO_APP_DB_PASSWORD
                        valueFrom:
                          secretKeyRef:
                            name: demo-app-db-user
                            key: password

    # ==========================================================================
    # WAIT FOR RAYJOB COMPLETION
    #
    # Uses Ray CLI for log streaming and kubectl for status polling.
    # Parses ##DVC_CHANGED=true/false## marker from logs to detect if
    # the pipeline produced new outputs or hit DVC cache.
    # ==========================================================================
    - name: wait-for-rayjob
      inputs:
        parameters:
          - name: job_name
          - name: timeout_seconds
            default: "3600"
      outputs:
        parameters:
          - name: job_status
            valueFrom:
              path: /tmp/job-status.txt
          - name: dvc_changed
            valueFrom:
              path: /tmp/dvc-changed.txt
      script:
        image: rayproject/ray:2.51.0-py312
        command: [bash]
        source: |
          JOB_NAME="{{inputs.parameters.job_name}}"
          TIMEOUT="{{inputs.parameters.timeout_seconds}}"

          # Initialize outputs
          echo "PENDING" > /tmp/job-status.txt
          echo "false" > /tmp/dvc-changed.txt

          # Install kubectl
          wget -q "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl" -O /tmp/kubectl
          chmod +x /tmp/kubectl

          # Wait for Ray job ID and cluster name from the RayJob CR
          ELAPSED=0
          while [ $ELAPSED -lt 300 ]; do
            RAY_JOB_ID=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobId}' 2>/dev/null || echo "")
            CLUSTER_NAME=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.rayClusterName}' 2>/dev/null || echo "")
            DEPLOY_STATUS=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobDeploymentStatus}' 2>/dev/null || echo "")

            if [ "$DEPLOY_STATUS" = "Failed" ]; then
              echo "ERROR: RayJob deployment failed"
              /tmp/kubectl describe rayjob -n mlops "$JOB_NAME"
              echo "FAILED" > /tmp/job-status.txt
              exit 1
            fi

            if [ -n "$RAY_JOB_ID" ] && [ -n "$CLUSTER_NAME" ]; then
              break
            fi
            echo "Waiting for job to initialize... (${ELAPSED}s)"
            sleep 5
            ELAPSED=$((ELAPSED + 5))
          done

          if [ -z "$RAY_JOB_ID" ] || [ -z "$CLUSTER_NAME" ]; then
            echo "ERROR: Timeout waiting for job"
            echo "FAILED" > /tmp/job-status.txt
            exit 1
          fi

          RAY_ADDRESS="http://${CLUSTER_NAME}-head-svc.mlops.svc.cluster.local:8265"
          echo "=========================================="
          echo "Job ID:  $RAY_JOB_ID"
          echo "Cluster: $CLUSTER_NAME"
          echo "Address: $RAY_ADDRESS"
          echo "=========================================="

          # Stream logs in background for real-time output
          ray job logs -f "$RAY_JOB_ID" --address "$RAY_ADDRESS" &
          LOG_PID=$!

          # Poll job status via kubectl (authoritative source)
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT ]; do
            JOB_STATUS=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo "")

            if [ "$JOB_STATUS" = "SUCCEEDED" ]; then
              echo "SUCCEEDED" > /tmp/job-status.txt

              # Give logs time to flush before fetching
              sleep 2

              # Fetch complete logs and parse DVC_CHANGED marker
              FULL_LOGS=$(ray job logs "$RAY_JOB_ID" --address "$RAY_ADDRESS" 2>/dev/null || echo "")
              if echo "$FULL_LOGS" | grep -q "##DVC_CHANGED=true##"; then
                echo "true" > /tmp/dvc-changed.txt
                echo ""
                echo "=========================================="
                echo "SUCCESS: Pipeline produced new outputs"
                echo "=========================================="
              elif echo "$FULL_LOGS" | grep -q "##DVC_CHANGED=false##"; then
                echo "false" > /tmp/dvc-changed.txt
                echo ""
                echo "=========================================="
                echo "SUCCESS: Pipeline cache hit (no new outputs)"
                echo "=========================================="
              else
                # Marker not found - default to true to be safe
                echo "true" > /tmp/dvc-changed.txt
                echo ""
                echo "=========================================="
                echo "SUCCESS: Job completed (marker not found, assuming changed)"
                echo "=========================================="
              fi

              kill $LOG_PID 2>/dev/null || true
              exit 0
            fi

            if [ "$JOB_STATUS" = "FAILED" ] || [ "$JOB_STATUS" = "STOPPED" ]; then
              echo "FAILED" > /tmp/job-status.txt
              echo ""
              echo "=========================================="
              echo "FAILED: Job status is $JOB_STATUS"
              echo "=========================================="
              /tmp/kubectl describe rayjob -n mlops "$JOB_NAME"
              kill $LOG_PID 2>/dev/null || true
              exit 1
            fi

            sleep 5
            ELAPSED=$((ELAPSED + 5))
          done

          echo "FAILED" > /tmp/job-status.txt
          echo "TIMEOUT after ${TIMEOUT}s"
          kill $LOG_PID 2>/dev/null || true
          exit 1
