apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: data-templates
  namespace: mlops
  annotations:
    workflows.argoproj.io/description: "Reusable DVC data pipeline operations"
spec:
  serviceAccountName: workflow-executor

  templates:
    # --------------------------------------------------------------------------
    # Run a DVC pipeline (dvc repro)
    # --------------------------------------------------------------------------
    - name: run-dvc-pipeline
      inputs:
        parameters:
          - name: repo_path
            description: "Path to cloned repo"
          - name: pipeline_name
            description: "Pipeline folder name under pipelines/"
          - name: force
            default: "false"
          - name: image
            default: "opencloudhuborg/data-registry-pipelines:latest"
          - name: cpu_request
            default: "500m"
          - name: cpu_limit
            default: "2"
          - name: memory_request
            default: "1Gi"
          - name: memory_limit
            default: "4Gi"
        artifacts:
          - name: repo
            path: "{{inputs.parameters.repo_path}}"
      outputs:
        parameters:
          - name: changed
            valueFrom:
              path: /tmp/changed.txt
          - name: hash_before
            valueFrom:
              path: /tmp/hash_before.txt
          - name: hash_after
            valueFrom:
              path: /tmp/hash_after.txt
        artifacts:
          - name: repo
            path: "{{inputs.parameters.repo_path}}"
      script:
        image: "{{inputs.parameters.image}}"
        command: [bash]
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: accesskey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: secretkey
          - name: AWS_ENDPOINT_URL
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: endpoint-url
        source: |
          set -e

          PIPELINE="{{inputs.parameters.pipeline_name}}"
          FORCE="{{inputs.parameters.force}}"
          REPO_PATH="{{inputs.parameters.repo_path}}"

          echo "false" > /tmp/changed.txt
          echo "" > /tmp/hash_before.txt
          echo "" > /tmp/hash_after.txt

          cd "$REPO_PATH"

          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸš€ Running DVC pipeline: $PIPELINE"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

          # Configure DVC remote
          dvc remote modify minio endpointurl "$AWS_ENDPOINT_URL"
          dvc remote modify minio access_key_id "$AWS_ACCESS_KEY_ID"
          dvc remote modify minio secret_access_key "$AWS_SECRET_ACCESS_KEY"

          # Hash before
          LOCK_FILE="pipelines/${PIPELINE}/dvc.lock"
          if [ -f "$LOCK_FILE" ]; then
            md5sum "$LOCK_FILE" | cut -d' ' -f1 > /tmp/hash_before.txt
            echo "ðŸ“¦ Hash before: $(cat /tmp/hash_before.txt)"
          else
            echo "ðŸ“¦ No existing dvc.lock"
          fi

          # Run DVC
          FORCE_FLAG=""
          if [ "$FORCE" = "true" ]; then
            FORCE_FLAG="--force"
            echo "âš ï¸  Force mode enabled"
          fi

          echo "ðŸ”„ Running dvc repro..."
          dvc repro $FORCE_FLAG "pipelines/${PIPELINE}/dvc.yaml"

          # Hash after
          if [ -f "$LOCK_FILE" ]; then
            md5sum "$LOCK_FILE" | cut -d' ' -f1 > /tmp/hash_after.txt
            echo "ðŸ“¦ Hash after: $(cat /tmp/hash_after.txt)"
          fi

          # Check if changed
          HASH_BEFORE=$(cat /tmp/hash_before.txt)
          HASH_AFTER=$(cat /tmp/hash_after.txt)

          if [ "$HASH_BEFORE" != "$HASH_AFTER" ]; then
            echo "true" > /tmp/changed.txt
            echo "ðŸ“ dvc.lock changed"
          else
            echo "â„¹ï¸  No changes detected"
          fi

          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "âœ… Pipeline $PIPELINE complete"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        resources:
          requests:
            cpu: "{{inputs.parameters.cpu_request}}"
            memory: "{{inputs.parameters.memory_request}}"
          limits:
            cpu: "{{inputs.parameters.cpu_limit}}"
            memory: "{{inputs.parameters.memory_limit}}"

    # --------------------------------------------------------------------------
    # Push data to DVC remote
    # --------------------------------------------------------------------------
    - name: dvc-push
      inputs:
        parameters:
          - name: repo_path
            description: "Path to cloned repo"
          - name: image
            default: "opencloudhuborg/data-registry-pipelines:latest"
        artifacts:
          - name: repo
            path: "{{inputs.parameters.repo_path}}"
      outputs:
        artifacts:
          - name: repo
            path: "{{inputs.parameters.repo_path}}"
      script:
        image: "{{inputs.parameters.image}}"
        command: [bash]
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: accesskey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: secretkey
          - name: AWS_ENDPOINT_URL
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: endpoint-url
        source: |
          set -e

          cd "{{inputs.parameters.repo_path}}"

          echo "ðŸ“¤ Pushing data to DVC remote..."

          # Configure DVC remote
          dvc remote modify minio endpointurl "$AWS_ENDPOINT_URL"
          dvc remote modify minio access_key_id "$AWS_ACCESS_KEY_ID"
          dvc remote modify minio secret_access_key "$AWS_SECRET_ACCESS_KEY"

          dvc push

          echo "âœ… Data pushed to MinIO"
        resources:
          requests:
            cpu: "200m"
            memory: "512Mi"
          limits:
            cpu: "1"
            memory: "2Gi"

    # --------------------------------------------------------------------------
    # Pull data from DVC remote
    # --------------------------------------------------------------------------
    - name: dvc-pull
      inputs:
        parameters:
          - name: repo_path
            description: "Path to cloned repo"
          - name: image
            default: "opencloudhuborg/data-registry-pipelines:latest"
        artifacts:
          - name: repo
            path: "{{inputs.parameters.repo_path}}"
      outputs:
        artifacts:
          - name: repo
            path: "{{inputs.parameters.repo_path}}"
      script:
        image: "{{inputs.parameters.image}}"
        command: [bash]
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: accesskey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: secretkey
          - name: AWS_ENDPOINT_URL
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: endpoint-url
        source: |
          set -e

          cd "{{inputs.parameters.repo_path}}"

          echo "ðŸ“¥ Pulling data from DVC remote..."

          # Configure DVC remote
          dvc remote modify minio endpointurl "$AWS_ENDPOINT_URL"
          dvc remote modify minio access_key_id "$AWS_ACCESS_KEY_ID"
          dvc remote modify minio secret_access_key "$AWS_SECRET_ACCESS_KEY"

          dvc pull

          echo "âœ… Data pulled from MinIO"
        resources:
          requests:
            cpu: "200m"
            memory: "512Mi"
          limits:
            cpu: "1"
            memory: "2Gi"

    # --------------------------------------------------------------------------
    # Map pipeline name to dataset name
    # --------------------------------------------------------------------------
    - name: map-pipeline-to-dataset
      inputs:
        parameters:
          - name: pipeline_name
          - name: pipeline_map
            default: '{"opencloudhub-readmes-download":"opencloudhub-readmes"}'
      outputs:
        parameters:
          - name: dataset
            valueFrom:
              path: /tmp/dataset.txt
      script:
        image: alpine:latest
        command: [sh]
        source: |
          set -e
          apk add --no-cache jq >/dev/null 2>&1

          PIPELINE="{{inputs.parameters.pipeline_name}}"
          MAP='{{inputs.parameters.pipeline_map}}'

          # Try to get from map, fallback to pipeline name
          DATASET=$(echo "$MAP" | jq -r ".\"$PIPELINE\" // \"$PIPELINE\"")

          echo "$DATASET" > /tmp/dataset.txt
          echo "ðŸ“¦ Pipeline '$PIPELINE' -> Dataset '$DATASET'"
