apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: embeddings-pipeline
  namespace: mlops
  annotations:
    workflows.argoproj.io/description: 'Use Ray Data to create embeddings for Readmes and store them in pgvector.'
spec:
  serviceAccountName: workflow-executor

  arguments:
    parameters:
      - name: data_version
      - name: compute_type
        value: "cpu-medium"
      - name: image
        value: "opencloudhuborg/data-registry-pipelines:latest"

  entrypoint: main

  templates:
    - name: main
      inputs:
        parameters:
          - name: data_version
            default: "{{workflow.parameters.data_version}}"
          - name: compute_type
            default: "{{workflow.parameters.compute_type}}"
          - name: image
            default: "{{workflow.parameters.image}}"
      steps:
        - - name: map-compute
            templateRef:
              name: compute-templates
              template: map-compute-config
            arguments:
              parameters:
                - name: compute_type
                  value: "{{inputs.parameters.compute_type}}"

        - - name: run-embeddings
            template: run-ray-job
            arguments:
              parameters:
                - name: data_version
                  value: "{{inputs.parameters.data_version}}"
                - name: image
                  value: "{{inputs.parameters.image}}"
                - name: cpu_request
                  value: "{{steps.map-compute.outputs.parameters.cpu_request}}"
                - name: cpu_limit
                  value: "{{steps.map-compute.outputs.parameters.cpu_limit}}"
                - name: memory_request
                  value: "{{steps.map-compute.outputs.parameters.memory_request}}"
                - name: memory_limit
                  value: "{{steps.map-compute.outputs.parameters.memory_limit}}"
                - name: replicas
                  value: "{{steps.map-compute.outputs.parameters.replicas}}"

        - - name: create-tag
            templateRef:
              name: git-templates
              template: create-tag
            arguments:
              parameters:
                - name: tag_prefix
                  value: "opencloudhub-readmes-embeddings"
                - name: message
                  value: "Embeddings from {{inputs.parameters.data_version}}"

    - name: run-ray-job
      inputs:
        parameters:
          - name: data_version
          - name: image
          - name: cpu_request
          - name: cpu_limit
          - name: memory_request
          - name: memory_limit
          - name: replicas
      script:
        image: bitnami/kubectl:latest
        command: [sh]
        source: |
          set -e

          DATA_VERSION="{{inputs.parameters.data_version}}"
          IMAGE="{{inputs.parameters.image}}"
          RUN_ID="emb-$(date +%s)"

          echo "üß† Embeddings: ${DATA_VERSION}"

          cat <<EOF | kubectl create -f -
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            generateName: embeddings-
            namespace: mlops
            labels:
              run-id: "${RUN_ID}"
              argo-workflow: "{{workflow.uid}}"
          spec:
            entrypoint: |
              sed -i 's/version: .*/version: "${DATA_VERSION}"/' pipelines/opencloudhub-readmes-embeddings/params.yaml &&
              dvc repro pipelines/opencloudhub-readmes-embeddings/dvc.yaml
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.51.0"
              headGroupSpec:
                rayStartParams:
                  dashboard-host: "0.0.0.0"
                  num-cpus: "0"
                template:
                  spec:
                    containers:
                      - name: ray-head
                        image: ${IMAGE}
                        imagePullPolicy: Always
                        ports:
                          - containerPort: 6379
                            name: gcs
                          - containerPort: 8265
                            name: dashboard
                          - containerPort: 10001
                            name: client
                        livenessProbe:
                          exec:
                            command: ["ray", "status"]
                          initialDelaySeconds: 30
                          periodSeconds: 10
                          timeoutSeconds: 10
                          failureThreshold: 12
                        readinessProbe:
                          exec:
                            command: ["ray", "status"]
                          initialDelaySeconds: 10
                          periodSeconds: 5
                          timeoutSeconds: 5
                          failureThreshold: 12
                        resources:
                          requests:
                            cpu: "{{inputs.parameters.cpu_request}}"
                            memory: "{{inputs.parameters.memory_request}}"
                          limits:
                            cpu: "{{inputs.parameters.cpu_limit}}"
                            memory: "{{inputs.parameters.memory_limit}}"
                        env:
                          - name: DVC_REPO
                            value: "https://github.com/OpenCloudHub/data-registry.git"
                          - name: AWS_ACCESS_KEY_ID
                            valueFrom:
                              secretKeyRef:
                                name: minio-tenant-secret
                                key: accesskey
                          - name: AWS_SECRET_ACCESS_KEY
                            valueFrom:
                              secretKeyRef:
                                name: minio-tenant-secret
                                key: secretkey
                          - name: AWS_ENDPOINT_URL
                            value: "https://minio-api.internal.opencloudhub.org"
                          - name: PGVECTOR_HOST
                            value: "demo-app-db-rw.storage.svc.cluster.local"
                          - name: POSTGRES_DEMO_APP_DB_PASSWORD
                            valueFrom:
                              secretKeyRef:
                                name: demo-app-db-user
                                key: password
              workerGroupSpecs:
                - replicas: {{inputs.parameters.replicas}}
                  groupName: worker
                  rayStartParams: {}
                  template:
                    spec:
                      containers:
                        - name: ray-worker
                          image: ${IMAGE}
                          imagePullPolicy: Always
                          livenessProbe:
                            exec:
                              command: ["ray", "status"]
                            initialDelaySeconds: 30
                            periodSeconds: 10
                            timeoutSeconds: 10
                            failureThreshold: 12
                          readinessProbe:
                            exec:
                              command: ["ray", "status"]
                            initialDelaySeconds: 10
                            periodSeconds: 5
                            timeoutSeconds: 5
                            failureThreshold: 12
                          resources:
                            requests:
                              cpu: "{{inputs.parameters.cpu_request}}"
                              memory: "{{inputs.parameters.memory_request}}"
                            limits:
                              cpu: "{{inputs.parameters.cpu_limit}}"
                              memory: "{{inputs.parameters.memory_limit}}"
                          env:
                            - name: DVC_REPO
                              value: "https://github.com/OpenCloudHub/data-registry.git"
                            - name: AWS_ACCESS_KEY_ID
                              valueFrom:
                                secretKeyRef:
                                  name: minio-tenant-secret
                                  key: accesskey
                            - name: AWS_SECRET_ACCESS_KEY
                              valueFrom:
                                secretKeyRef:
                                  name: minio-tenant-secret
                                  key: secretkey
                            - name: AWS_ENDPOINT_URL
                              value: "https://minio-api.internal.opencloudhub.org"
                            - name: PGVECTOR_HOST
                              value: "demo-app-db-rw.storage.svc.cluster.local"
                            - name: POSTGRES_DEMO_APP_DB_PASSWORD
                              valueFrom:
                                secretKeyRef:
                                  name: demo-app-db-user
                                  key: password
          EOF

          sleep 5
          JOB=$(kubectl get rayjobs -n mlops -l run-id="${RUN_ID}" -o jsonpath='{.items[0].metadata.name}')
          echo "RayJob: $JOB"

          # Wait for job to be submitted
          echo "‚è≥ Waiting for job submission..."
          MAX_WAIT=600
          ELAPSED=0
          while [ $ELAPSED -lt $MAX_WAIT ]; do
            STATUS=$(kubectl get rayjob -n mlops $JOB -o jsonpath='{.status.jobDeploymentStatus}' 2>/dev/null || echo "")
            if [ "$STATUS" = "Running" ] || [ "$STATUS" = "Complete" ]; then
              echo "‚úÖ Job submitted"
              break
            fi
            sleep 5
            ELAPSED=$((ELAPSED + 5))
            echo "‚è≥ Deployment status: $STATUS"
          done

          if [ $ELAPSED -ge $MAX_WAIT ]; then
            echo "‚ùå Timeout waiting for submission"
            kubectl describe rayjob -n mlops $JOB
            exit 1
          fi

          # Find submitter pod and stream logs
          SUBMITTER=$(kubectl get pods -n mlops --no-headers | grep "${JOB}" | grep -v head | grep -v worker | awk '{print $1}' | head -1)

          if [ -n "$SUBMITTER" ]; then
            echo "üìã Streaming logs from: $SUBMITTER"
            kubectl logs -n mlops $SUBMITTER -f 2>/dev/null &
            LOG_PID=$!
          fi

          # Wait for completion
          TIMEOUT=1800
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT ]; do
            STATUS=$(kubectl get rayjob -n mlops $JOB -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo "PENDING")
            case "$STATUS" in
              SUCCEEDED)
                sleep 5
                [ -n "$LOG_PID" ] && kill $LOG_PID 2>/dev/null || true
                echo "‚úÖ Done"
                exit 0
                ;;
              FAILED|STOPPED)
                [ -n "$LOG_PID" ] && kill $LOG_PID 2>/dev/null || true
                echo "‚ùå $STATUS"
                kubectl describe rayjob -n mlops $JOB
                # Try to get head pod logs
                HEAD_POD=$(kubectl get pods -n mlops -l ray.io/cluster=$JOB -l ray.io/node-type=head -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
                if [ -n "$HEAD_POD" ]; then
                  echo "=== Head pod logs ==="
                  kubectl logs -n mlops $HEAD_POD --tail=100 2>/dev/null || true
                fi
                exit 1
                ;;
              *)
                sleep 15
                ELAPSED=$((ELAPSED + 15))
                ;;
            esac
          done

          [ -n "$LOG_PID" ] && kill $LOG_PID 2>/dev/null || true
          echo "‚ùå Timeout"
          exit 1
