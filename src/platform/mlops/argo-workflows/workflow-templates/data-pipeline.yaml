apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: data-pipeline
  namespace: mlops
  annotations:
    workflows.argoproj.io/title: '**Data Pipeline**'
    workflows.argoproj.io/description: 'Run DVC pipelines, push, commit, tag, and trigger embeddings.'
spec:
  serviceAccountName: workflow-executor

  arguments:
    parameters:
      - name: pipelines
        value: '["emotion","fashion-mnist","wine-quality","opencloudhub-readmes-download"]'
      - name: force
        value: "false"
      - name: bump_type
        value: "patch"
      - name: is_automated
        value: "false"
      - name: trigger_embeddings
        value: "true"
      - name: image
        value: "opencloudhuborg/data-registry-pipelines:latest"

  entrypoint: main

  volumeClaimTemplates:
    - metadata:
        name: workspace
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 5Gi

  templates:
    - name: main
      steps:
        - - name: clone-repo
            template: clone-repo
        - - name: run-pipelines
            template: run-single-pipeline
            arguments:
              parameters:
                - name: pipeline_name
                  value: "{{item}}"
            withParam: "{{workflow.parameters.pipelines}}"
        - - name: push-data
            template: push-data
        - - name: detect-changes
            template: detect-changes
        - - name: commit-and-tag
            template: commit-and-tag
            when: "{{steps.detect-changes.outputs.parameters.has_changes}} == true"
        - - name: embeddings
            template: run-embeddings
            arguments:
              parameters:
                - name: changed_datasets
                  value: "{{steps.detect-changes.outputs.parameters.changed_datasets}}"
            when: "{{workflow.parameters.trigger_embeddings}} == true && {{steps.detect-changes.outputs.parameters.has_changes}} == true"

    # ----------------------------------------------------------------------
    # Clone repo - just volumeMounts, no volumes declaration
    # ----------------------------------------------------------------------
    - name: clone-repo
      script:
        image: alpine/git:latest
        command: [sh]
        volumeMounts:
          - name: workspace
            mountPath: /workspace
          - name: git-secret
            mountPath: /mnt/secrets
            readOnly: true
        source: |
          set -e

          mkdir -p ~/.ssh
          cat /mnt/secrets/sshPrivateKey > ~/.ssh/id_ed25519
          echo "" >> ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan github.com >> ~/.ssh/known_hosts

          echo "ðŸ“¥ Cloning repository..."
          git clone git@github.com:OpenCloudHub/data-registry.git /workspace/repo
          cd /workspace/repo

          git config user.name "Argo Workflow"
          git config user.email "workflow@opencloudhub.org"

          echo "âœ… Repository cloned to /workspace/repo"
      volumes:
        - name: git-secret
          secret:
            secretName: data-registry-repo

    # ----------------------------------------------------------------------
    # Run single pipeline
    # ----------------------------------------------------------------------
    - name: run-single-pipeline
      inputs:
        parameters:
          - name: pipeline_name
      container:
        image: "{{workflow.parameters.image}}"
        command: ["bash", "-c"]
        workingDir: /workspace/repo
        args:
          - |
            set -e
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ðŸš€ Running DVC pipeline: {{inputs.parameters.pipeline_name}}"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            dvc remote modify minio endpointurl $AWS_ENDPOINT_URL
            dvc remote modify minio access_key_id $AWS_ACCESS_KEY_ID
            dvc remote modify minio secret_access_key $AWS_SECRET_ACCESS_KEY

            FORCE_FLAG=""
            if [ "{{workflow.parameters.force}}" = "true" ]; then
              FORCE_FLAG="--force"
              echo "âš ï¸  Force mode enabled"
            fi

            dvc repro $FORCE_FLAG pipelines/{{inputs.parameters.pipeline_name}}/dvc.yaml
            echo "âœ… Pipeline {{inputs.parameters.pipeline_name}} complete"
        volumeMounts:
          - name: workspace
            mountPath: /workspace
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: accesskey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: secretkey
          - name: AWS_ENDPOINT_URL
            value: "https://minio-api.internal.opencloudhub.org"
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "2"
            memory: "4Gi"

    # ----------------------------------------------------------------------
    # Push data
    # ----------------------------------------------------------------------
    - name: push-data
      container:
        image: "{{workflow.parameters.image}}"
        command: ["bash", "-c"]
        workingDir: /workspace/repo
        args:
          - |
            set -e
            echo "ðŸ“¤ Pushing data to remote storage..."
            dvc remote modify minio endpointurl $AWS_ENDPOINT_URL
            dvc remote modify minio access_key_id $AWS_ACCESS_KEY_ID
            dvc remote modify minio secret_access_key $AWS_SECRET_ACCESS_KEY
            dvc push
            echo "âœ… Data pushed to MinIO"
        volumeMounts:
          - name: workspace
            mountPath: /workspace
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: accesskey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: minio-tenant-secret
                key: secretkey
          - name: AWS_ENDPOINT_URL
            value: "https://minio-api.internal.opencloudhub.org"
        resources:
          requests:
            cpu: "200m"
            memory: "512Mi"
          limits:
            cpu: "1"
            memory: "1Gi"

    # ----------------------------------------------------------------------
    # Detect changes
    # ----------------------------------------------------------------------
    - name: detect-changes
      outputs:
        parameters:
          - name: changed_datasets
            valueFrom:
              path: /tmp/changed_datasets.json
          - name: has_changes
            valueFrom:
              path: /tmp/has_changes.txt
      script:
        image: "{{workflow.parameters.image}}"
        command: [bash]
        workingDir: /workspace/repo
        volumeMounts:
          - name: workspace
            mountPath: /workspace
        source: |
          set -e

          echo "[]" > /tmp/changed_datasets.json
          echo "false" > /tmp/has_changes.txt

          PIPELINE_MAP='{"opencloudhub-readmes-download":"opencloudhub-readmes"}'

          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸ” Detecting DVC changes..."
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

          GIT_STATUS=$(git status --porcelain | grep "dvc.lock" || true)
          echo "Git status (dvc.lock files):"
          echo "${GIT_STATUS:-No changes}"

          if [ -z "$GIT_STATUS" ]; then
            echo ""
            echo "â„¹ï¸  No dvc.lock changes detected"
            exit 0
          fi

          echo "true" > /tmp/has_changes.txt

          DATASETS="[]"
          for lock_file in $(echo "$GIT_STATUS" | awk '{print $2}'); do
            PIPELINE=$(echo "$lock_file" | cut -d'/' -f2)
            DATASET=$(echo "$PIPELINE_MAP" | jq -r ".\"$PIPELINE\" // \"$PIPELINE\"")
            DATASETS=$(echo "$DATASETS" | jq --arg d "$DATASET" '. + [$d] | unique')
          done

          echo "$DATASETS" > /tmp/changed_datasets.json

          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸ“ Changed datasets: $DATASETS"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    # ----------------------------------------------------------------------
    # Commit and tag
    # ----------------------------------------------------------------------
    - name: commit-and-tag
      outputs:
        parameters:
          - name: readmes_tag
            valueFrom:
              path: /tmp/readmes_tag.txt
      volumes:
        - name: git-secret
          secret:
            secretName: data-registry-repo
      script:
        image: alpine/git:latest
        command: [sh]
        workingDir: /workspace/repo
        volumeMounts:
          - name: workspace
            mountPath: /workspace
          - name: git-secret
            mountPath: /mnt/secrets
            readOnly: true
        source: |
          set -e
          apk add --no-cache jq >/dev/null 2>&1

          echo "" > /tmp/readmes_tag.txt

          mkdir -p ~/.ssh
          cat /mnt/secrets/sshPrivateKey > ~/.ssh/id_ed25519
          echo "" >> ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan github.com >> ~/.ssh/known_hosts

          PIPELINE_MAP='{"opencloudhub-readmes-download":"opencloudhub-readmes"}'
          BUMP_TYPE="{{workflow.parameters.bump_type}}"
          IS_AUTOMATED="{{workflow.parameters.is_automated}}"
          [ "$IS_AUTOMATED" = "true" ] && SUFFIX="-automated" || SUFFIX=""

          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸ“ Committing changes..."
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

          CHANGED=$(git status --porcelain | grep "dvc.lock" || true)

          git add .
          git commit -m "chore: update data [skip ci]"
          git push origin main
          echo "âœ… Committed and pushed"

          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸ·ï¸  Creating tags..."
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

          for lock_file in $(echo "$CHANGED" | awk '{print $2}'); do
            PIPELINE=$(echo "$lock_file" | cut -d'/' -f2)
            DATASET=$(echo "$PIPELINE_MAP" | jq -r ".\"$PIPELINE\" // \"$PIPELINE\"")

            LATEST=$(git tag -l "${DATASET}-v*" --sort=-version:refname | head -n1 || echo "")

            if [ -z "$LATEST" ]; then
              VERSION="1.0.0"
            else
              CURRENT=$(echo "$LATEST" | sed "s/${DATASET}-v//" | sed 's/-automated//')
              MAJOR=$(echo "$CURRENT" | cut -d. -f1)
              MINOR=$(echo "$CURRENT" | cut -d. -f2)
              PATCH=$(echo "$CURRENT" | cut -d. -f3)

              case "$BUMP_TYPE" in
                major) VERSION="$((MAJOR + 1)).0.0" ;;
                minor) VERSION="${MAJOR}.$((MINOR + 1)).0" ;;
                patch) VERSION="${MAJOR}.${MINOR}.$((PATCH + 1))" ;;
              esac
            fi

            NEW_TAG="${DATASET}-v${VERSION}${SUFFIX}"

            if git tag -l "$NEW_TAG" | grep -q "$NEW_TAG"; then
              echo "â„¹ï¸  Tag $NEW_TAG already exists"
            else
              git tag -a "$NEW_TAG" -m "${DATASET} v${VERSION}"
              git push origin "$NEW_TAG"
              echo "âœ… Created: $NEW_TAG"
            fi

            if [ "$DATASET" = "opencloudhub-readmes" ]; then
              echo "$NEW_TAG" > /tmp/readmes_tag.txt
            fi
          done

          echo ""
          echo "âœ… All done!"

    # ----------------------------------------------------------------------
    # Run embeddings
    # ----------------------------------------------------------------------
    - name: run-embeddings
      inputs:
        parameters:
          - name: changed_datasets
      steps:
        - - name: check-readmes
            template: contains-dataset
            arguments:
              parameters:
                - name: datasets
                  value: "{{inputs.parameters.changed_datasets}}"
                - name: target
                  value: "opencloudhub-readmes"

        - - name: get-tag
            templateRef:
              name: git-templates
              template: get-latest-tag
            arguments:
              parameters:
                - name: tag_prefix
                  value: "opencloudhub-readmes"
            when: "{{steps.check-readmes.outputs.result}} == true"

        - - name: run
            templateRef:
              name: embeddings-pipeline
              template: main
            arguments:
              parameters:
                - name: data_version
                  value: "{{steps.get-tag.outputs.parameters.latest_tag}}"
                - name: compute_type
                  value: "cpu-small"
                - name: image
                  value: "{{workflow.parameters.image}}"
            when: "{{steps.check-readmes.outputs.result}} == true"

    # ----------------------------------------------------------------------
    # Helper
    # ----------------------------------------------------------------------
    - name: contains-dataset
      inputs:
        parameters:
          - name: datasets
          - name: target
      script:
        image: alpine:latest
        command: [sh]
        source: |
          apk add --no-cache jq >/dev/null 2>&1
          echo '{{inputs.parameters.datasets}}' | jq -e 'index("{{inputs.parameters.target}}") != null' >/dev/null && echo -n "true" || echo -n "false"
