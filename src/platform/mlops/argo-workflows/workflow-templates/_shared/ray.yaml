# =============================================================================
# Shared Ray Job Templates
# =============================================================================

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ray-templates
  namespace: mlops
spec:
  templates:
    # =========================================================================
    # MAIN: Submit and wait with log streaming (DAG for proper output resolution)
    # =========================================================================
    - name: training-job
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: model_configmap
          - name: cpu
            default: "2"
          - name: memory
            default: "4Gi"
          - name: gpu
            default: "0"
          - name: replicas
            default: "1"
          - name: dvc_data_version
          - name: timeout
            default: "3600"

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              parameter: "{{tasks.submit.outputs.parameters.job_name}}"
          - name: job_status
            valueFrom:
              parameter: "{{tasks.wait.outputs.parameters.job_status}}"

      dag:
        tasks:
          - name: submit
            template: submit-rayjob
            arguments:
              parameters:
                - name: job_prefix
                  value: "{{inputs.parameters.job_prefix}}"
                - name: image
                  value: "{{inputs.parameters.image}}"
                - name: entrypoint
                  value: "{{inputs.parameters.entrypoint}}"
                - name: model_configmap
                  value: "{{inputs.parameters.model_configmap}}"
                - name: cpu
                  value: "{{inputs.parameters.cpu}}"
                - name: memory
                  value: "{{inputs.parameters.memory}}"
                - name: gpu
                  value: "{{inputs.parameters.gpu}}"
                - name: replicas
                  value: "{{inputs.parameters.replicas}}"
                - name: dvc_data_version
                  value: "{{inputs.parameters.dvc_data_version}}"

          - name: wait
            dependencies: [submit]
            template: stream-and-wait
            arguments:
              parameters:
                - name: job_name
                  value: "{{tasks.submit.outputs.parameters.job_name}}"
                - name: timeout
                  value: "{{inputs.parameters.timeout}}"

    # =========================================================================
    # SUBMIT: Create RayJob (clean resource template)
    # =========================================================================
    - name: submit-rayjob
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: model_configmap
          - name: cpu
          - name: memory
          - name: gpu
          - name: replicas
          - name: dvc_data_version

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              jsonPath: "{.metadata.name}"

      resource:
        action: create
        manifest: |
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            generateName: {{inputs.parameters.job_prefix}}-
            namespace: mlops
            labels:
              workflow: "{{workflow.name}}"
              workflow-uid: "{{workflow.uid}}"
          spec:
            entrypoint: "{{inputs.parameters.entrypoint}}"
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.41.0"
              headGroupSpec:
                rayStartParams:
                  dashboard-host: "0.0.0.0"
                template:
                  spec:
                    containers:
                      - name: ray-head
                        image: "{{inputs.parameters.image}}"
                        resources:
                          requests:
                            cpu: "{{inputs.parameters.cpu}}"
                            memory: "{{inputs.parameters.memory}}"
                          limits:
                            cpu: "{{inputs.parameters.cpu}}"
                            memory: "{{inputs.parameters.memory}}"
                            nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                        envFrom:
                          - configMapRef:
                              name: mlops-platform-env
                          - configMapRef:
                              name: "{{inputs.parameters.model_configmap}}"
                          - secretRef:
                              name: minio-tenant-secret
                        env:
                          - name: ARGO_WORKFLOW_UID
                            value: "{{workflow.uid}}"
                          - name: ARGO_WORKFLOW_NAME
                            value: "{{workflow.name}}"
                          - name: DOCKER_IMAGE_TAG
                            value: "{{inputs.parameters.image}}"
                          - name: DVC_DATA_VERSION
                            value: "{{inputs.parameters.dvc_data_version}}"
                          - name: REPLICAS
                            value: "{{inputs.parameters.replicas}}"
              workerGroupSpecs:
                - groupName: workers
                  replicas: {{inputs.parameters.replicas}}
                  rayStartParams: {}
                  template:
                    spec:
                      containers:
                        - name: ray-worker
                          image: "{{inputs.parameters.image}}"
                          resources:
                            requests:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                            limits:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                              nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                          envFrom:
                            - configMapRef:
                                name: mlops-platform-env
                            - configMapRef:
                                name: "{{inputs.parameters.model_configmap}}"
                            - secretRef:
                                name: minio-tenant-secret
                          env:
                            - name: ARGO_WORKFLOW_UID
                              value: "{{workflow.uid}}"
                            - name: ARGO_WORKFLOW_NAME
                              value: "{{workflow.name}}"
                            - name: DOCKER_IMAGE_TAG
                              value: "{{inputs.parameters.image}}"
                            - name: DVC_DATA_VERSION
                              value: "{{inputs.parameters.dvc_data_version}}"
                            - name: REPLICAS
                              value: "{{inputs.parameters.replicas}}"

    # =========================================================================
    # WAIT: Stream logs while waiting for completion
    # =========================================================================
    - name: stream-and-wait
      inputs:
        parameters:
          - name: job_name
          - name: timeout
            default: "3600"
      outputs:
        parameters:
          - name: job_status
            valueFrom:
              path: /tmp/job_status.txt
      script:
        image: bitnami/kubectl:latest
        command: [bash]
        source: |
          set -e

          JOB_NAME="{{inputs.parameters.job_name}}"
          TIMEOUT="{{inputs.parameters.timeout}}"

          echo "PENDING" > /tmp/job_status.txt

          echo "=========================================="
          echo "ðŸ“‹ RayJob: $JOB_NAME"
          echo "=========================================="

          # Wait for submitter pod to exist and be running
          echo "â³ Waiting for submitter pod..."
          ELAPSED=0
          SUBMITTER_POD=""
          while [ $ELAPSED -lt 120 ]; do
            # Submitter pod is {JOB_NAME}-{suffix}, excluding head/worker pods
            SUBMITTER_POD=$(kubectl get pods -n mlops -o name 2>/dev/null | grep "^pod/${JOB_NAME}-" | grep -v -- "-head-" | grep -v -- "-worker" | head -1 | sed 's|pod/||' || echo "")

            if [ -n "$SUBMITTER_POD" ]; then
              POD_PHASE=$(kubectl get pod -n mlops "$SUBMITTER_POD" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")
              echo "   Found: $SUBMITTER_POD (phase: $POD_PHASE)"
              if [ "$POD_PHASE" = "Running" ] || [ "$POD_PHASE" = "Succeeded" ]; then
                break
              fi
            fi

            sleep 3
            ELAPSED=$((ELAPSED + 3))
          done

          if [ -z "$SUBMITTER_POD" ]; then
            echo "âŒ Could not find submitter pod after ${ELAPSED}s"
            echo "Available pods:"
            kubectl get pods -n mlops | grep "$JOB_NAME" || echo "(none)"
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi

          echo ""
          echo "ðŸš€ Streaming logs from: $SUBMITTER_POD"
          echo ""
          echo "=========================================="
          echo "ðŸ“ TRAINING LOGS"
          echo "=========================================="

          # Stream logs - follows until pod completes
          kubectl logs -n mlops -f "$SUBMITTER_POD" 2>&1 || true

          echo ""
          echo "=========================================="

          # Check final status
          FINAL_STATUS=$(kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo "UNKNOWN")

          if [ "$FINAL_STATUS" = "SUCCEEDED" ]; then
            echo "âœ… Training completed successfully"
            echo "SUCCEEDED" > /tmp/job_status.txt
            exit 0
          else
            echo "âŒ Training failed: $FINAL_STATUS"
            kubectl describe rayjob -n mlops "$JOB_NAME" | tail -30
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi

          echo "=========================================="
          echo "=========================================="
          echo ""
