# =============================================================================
# Shared Ray Job Templates
# =============================================================================

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ray-templates
  namespace: mlops
spec:
  templates:
    # =========================================================================
    # MAIN: Submit and wait with log streaming (DAG for proper output resolution)
    # =========================================================================
    - name: training-job
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: model_configmap
          - name: cpu
            default: "2"
          - name: memory
            default: "4Gi"
          - name: gpu
            default: "0"
          - name: replicas
            default: "1"
          - name: dvc_data_version
          - name: timeout
            default: "3600"

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              parameter: "{{tasks.submit.outputs.parameters.job_name}}"
          - name: job_status
            valueFrom:
              parameter: "{{tasks.wait.outputs.parameters.job_status}}"

      dag:
        tasks:
          - name: submit
            template: submit-rayjob
            arguments:
              parameters:
                - name: job_prefix
                  value: "{{inputs.parameters.job_prefix}}"
                - name: image
                  value: "{{inputs.parameters.image}}"
                - name: entrypoint
                  value: "{{inputs.parameters.entrypoint}}"
                - name: model_configmap
                  value: "{{inputs.parameters.model_configmap}}"
                - name: cpu
                  value: "{{inputs.parameters.cpu}}"
                - name: memory
                  value: "{{inputs.parameters.memory}}"
                - name: gpu
                  value: "{{inputs.parameters.gpu}}"
                - name: replicas
                  value: "{{inputs.parameters.replicas}}"
                - name: dvc_data_version
                  value: "{{inputs.parameters.dvc_data_version}}"

          - name: wait
            dependencies: [submit]
            template: stream-and-wait
            arguments:
              parameters:
                - name: job_name
                  value: "{{tasks.submit.outputs.parameters.job_name}}"
                - name: timeout
                  value: "{{inputs.parameters.timeout}}"

    # =========================================================================
    # SUBMIT: Create RayJob (clean resource template)
    # =========================================================================
    - name: submit-rayjob
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: model_configmap
          - name: cpu
          - name: memory
          - name: gpu
          - name: replicas
          - name: dvc_data_version

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              jsonPath: "{.metadata.name}"

      resource:
        action: create
        manifest: |
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            generateName: {{inputs.parameters.job_prefix}}-
            namespace: mlops
            labels:
              workflow: "{{workflow.name}}"
              workflow-uid: "{{workflow.uid}}"
          spec:
            entrypoint: "{{inputs.parameters.entrypoint}}"
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.41.0"
              headGroupSpec:
                rayStartParams:
                  dashboard-host: "0.0.0.0"
                template:
                  spec:
                    containers:
                      - name: ray-head
                        image: "{{inputs.parameters.image}}"
                        resources:
                          requests:
                            cpu: "{{inputs.parameters.cpu}}"
                            memory: "{{inputs.parameters.memory}}"
                          limits:
                            cpu: "{{inputs.parameters.cpu}}"
                            memory: "{{inputs.parameters.memory}}"
                            nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                        envFrom:
                          - configMapRef:
                              name: mlops-platform-env
                          - configMapRef:
                              name: "{{inputs.parameters.model_configmap}}"
                          - secretRef:
                              name: minio-tenant-secret
                        env:
                          - name: ARGO_WORKFLOW_UID
                            value: "{{workflow.uid}}"
                          - name: ARGO_WORKFLOW_NAME
                            value: "{{workflow.name}}"
                          - name: DOCKER_IMAGE_TAG
                            value: "{{inputs.parameters.image}}"
                          - name: DVC_DATA_VERSION
                            value: "{{inputs.parameters.dvc_data_version}}"
                          - name: REPLICAS
                            value: "{{inputs.parameters.replicas}}"
              workerGroupSpecs:
                - groupName: workers
                  replicas: {{inputs.parameters.replicas}}
                  rayStartParams: {}
                  template:
                    spec:
                      containers:
                        - name: ray-worker
                          image: "{{inputs.parameters.image}}"
                          resources:
                            requests:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                            limits:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                              nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                          envFrom:
                            - configMapRef:
                                name: mlops-platform-env
                            - configMapRef:
                                name: "{{inputs.parameters.model_configmap}}"
                            - secretRef:
                                name: minio-tenant-secret
                          env:
                            - name: ARGO_WORKFLOW_UID
                              value: "{{workflow.uid}}"
                            - name: ARGO_WORKFLOW_NAME
                              value: "{{workflow.name}}"
                            - name: DOCKER_IMAGE_TAG
                              value: "{{inputs.parameters.image}}"
                            - name: DVC_DATA_VERSION
                              value: "{{inputs.parameters.dvc_data_version}}"
                            - name: REPLICAS
                              value: "{{inputs.parameters.replicas}}"

    # =========================================================================
    # WAIT: Stream logs while waiting for completion
    # =========================================================================
    - name: stream-and-wait
      inputs:
        parameters:
          - name: job_name
          - name: timeout
            default: "3600"
      outputs:
        parameters:
          - name: job_status
            valueFrom:
              path: /tmp/job_status.txt
      script:
        image: rayproject/ray:2.41.0-py312
        command: [bash]
        source: |
          set -e

          JOB_NAME="{{inputs.parameters.job_name}}"
          TIMEOUT="{{inputs.parameters.timeout}}"

          echo "PENDING" > /tmp/job_status.txt

          # Install kubectl
          wget -q "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl" -O /tmp/kubectl
          chmod +x /tmp/kubectl

          echo "=========================================="
          echo "ðŸ“‹ RayJob: $JOB_NAME"
          echo "=========================================="

          # Wait for job to initialize AND start running
          echo "â³ Waiting for job to start..."
          ELAPSED=0
          while [ $ELAPSED -lt 300 ]; do
            RAY_JOB_ID=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobId}' 2>/dev/null || echo "")
            CLUSTER_NAME=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.rayClusterName}' 2>/dev/null || echo "")
            JOB_STATUS=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo "")
            DEPLOY_STATUS=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobDeploymentStatus}' 2>/dev/null || echo "")

            echo "   Status: deploy=$DEPLOY_STATUS job=$JOB_STATUS (${ELAPSED}s)"

            if [ "$DEPLOY_STATUS" = "Failed" ] || [ "$JOB_STATUS" = "FAILED" ]; then
              echo "âŒ RayJob failed"
              /tmp/kubectl describe rayjob -n mlops "$JOB_NAME"
              echo "FAILED" > /tmp/job_status.txt
              exit 1
            fi

            # Wait until job is actually RUNNING
            if [ -n "$RAY_JOB_ID" ] && [ -n "$CLUSTER_NAME" ] && [ "$JOB_STATUS" = "RUNNING" ]; then
              break
            fi

            # Also break if already succeeded (fast jobs)
            if [ "$JOB_STATUS" = "SUCCEEDED" ]; then
              echo "âœ… Job completed quickly"
              echo "SUCCEEDED" > /tmp/job_status.txt
              exit 0
            fi

            sleep 5
            ELAPSED=$((ELAPSED + 5))
          done

          if [ -z "$RAY_JOB_ID" ] || [ -z "$CLUSTER_NAME" ]; then
            echo "âŒ Timeout waiting for job to initialize"
            /tmp/kubectl describe rayjob -n mlops "$JOB_NAME"
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi

          RAY_ADDRESS="http://${CLUSTER_NAME}-head-svc.mlops.svc.cluster.local:8265"

          echo ""
          echo "ðŸš€ Job running:"
          echo "   Ray Job ID: $RAY_JOB_ID"
          echo "   Cluster:    $CLUSTER_NAME"
          echo "   Address:    $RAY_ADDRESS"

          # Find submitter pod - it's {JOB_NAME}-{suffix} but NOT containing head/worker
          SUBMITTER_POD=$(/tmp/kubectl get pods -n mlops -o name | grep "^pod/${JOB_NAME}-" | grep -v "\-head-" | grep -v "\-worker" | head -1 | sed 's|pod/||')

          if [ -n "$SUBMITTER_POD" ]; then
            echo "   Submitter:  $SUBMITTER_POD"
          fi

          echo ""
          echo "=========================================="
          echo "ðŸ“ TRAINING LOGS"
          echo "=========================================="

          # Stream logs using ray CLI
          ray job logs "$RAY_JOB_ID" --address "$RAY_ADDRESS" --follow

          echo ""
          echo "=========================================="

          # Check final status
          FINAL_STATUS=$(/tmp/kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobStatus}')

          if [ "$FINAL_STATUS" = "SUCCEEDED" ]; then
            echo "âœ… Training completed successfully"
            echo "SUCCEEDED" > /tmp/job_status.txt
            exit 0
          else
            echo "âŒ Training failed: $FINAL_STATUS"
            /tmp/kubectl describe rayjob -n mlops "$JOB_NAME" | tail -30
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi
