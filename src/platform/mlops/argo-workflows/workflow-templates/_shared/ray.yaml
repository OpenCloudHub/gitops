# =============================================================================
# Shared Ray Job Templates
# =============================================================================

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ray-templates
  namespace: mlops
spec:
  templates:
    # =========================================================================
    # MAIN: Submit and wait with log streaming (DAG for proper output resolution)
    # =========================================================================
    - name: training-job
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: model_configmap
          - name: cpu
            default: "2"
          - name: memory
            default: "4Gi"
          - name: gpu
            default: "0"
          - name: replicas
            default: "1"
          - name: dvc_data_version
          - name: timeout
            default: "3600"

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              parameter: "{{tasks.submit.outputs.parameters.job_name}}"
          - name: job_status
            valueFrom:
              parameter: "{{tasks.wait.outputs.parameters.job_status}}"

      dag:
        tasks:
          - name: submit
            template: submit-rayjob
            arguments:
              parameters:
                - name: job_prefix
                  value: "{{inputs.parameters.job_prefix}}"
                - name: image
                  value: "{{inputs.parameters.image}}"
                - name: entrypoint
                  value: "{{inputs.parameters.entrypoint}}"
                - name: model_configmap
                  value: "{{inputs.parameters.model_configmap}}"
                - name: cpu
                  value: "{{inputs.parameters.cpu}}"
                - name: memory
                  value: "{{inputs.parameters.memory}}"
                - name: gpu
                  value: "{{inputs.parameters.gpu}}"
                - name: replicas
                  value: "{{inputs.parameters.replicas}}"
                - name: dvc_data_version
                  value: "{{inputs.parameters.dvc_data_version}}"

          - name: wait
            dependencies: [submit]
            template: stream-and-wait
            arguments:
              parameters:
                - name: job_name
                  value: "{{tasks.submit.outputs.parameters.job_name}}"
                - name: timeout
                  value: "{{inputs.parameters.timeout}}"

    # =========================================================================
    # SUBMIT: Create RayJob (clean resource template)
    # =========================================================================
    - name: submit-rayjob
      inputs:
        parameters:
          - name: job_prefix
          - name: image
          - name: entrypoint
          - name: model_configmap
          - name: cpu
          - name: memory
          - name: gpu
          - name: replicas
          - name: dvc_data_version

      outputs:
        parameters:
          - name: job_name
            valueFrom:
              jsonPath: "{.metadata.name}"

      resource:
        action: create
        manifest: |
          apiVersion: ray.io/v1
          kind: RayJob
          metadata:
            generateName: {{inputs.parameters.job_prefix}}-
            namespace: mlops
            labels:
              workflow: "{{workflow.name}}"
              workflow-uid: "{{workflow.uid}}"
          spec:
            entrypoint: "{{inputs.parameters.entrypoint}}"
            shutdownAfterJobFinishes: true
            ttlSecondsAfterFinished: 300
            rayClusterSpec:
              rayVersion: "2.41.0"
              headGroupSpec:
                rayStartParams:
                  dashboard-host: "0.0.0.0"
                template:
                  spec:
                    containers:
                      - name: ray-head
                        image: "{{inputs.parameters.image}}"
                        resources:
                          requests:
                            cpu: "{{inputs.parameters.cpu}}"
                            memory: "{{inputs.parameters.memory}}"
                          limits:
                            cpu: "{{inputs.parameters.cpu}}"
                            memory: "{{inputs.parameters.memory}}"
                            nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                        envFrom:
                          - configMapRef:
                              name: mlops-platform-env
                          - configMapRef:
                              name: "{{inputs.parameters.model_configmap}}"
                          - secretRef:
                              name: minio-tenant-secret
                        env:
                          - name: ARGO_WORKFLOW_UID
                            value: "{{workflow.uid}}"
                          - name: ARGO_WORKFLOW_NAME
                            value: "{{workflow.name}}"
                          - name: DOCKER_IMAGE_TAG
                            value: "{{inputs.parameters.image}}"
                          - name: DVC_DATA_VERSION
                            value: "{{inputs.parameters.dvc_data_version}}"
                          - name: REPLICAS
                            value: "{{inputs.parameters.replicas}}"
              workerGroupSpecs:
                - groupName: workers
                  replicas: {{inputs.parameters.replicas}}
                  rayStartParams: {}
                  template:
                    spec:
                      containers:
                        - name: ray-worker
                          image: "{{inputs.parameters.image}}"
                          resources:
                            requests:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                            limits:
                              cpu: "{{inputs.parameters.cpu}}"
                              memory: "{{inputs.parameters.memory}}"
                              nvidia.com/gpu: "{{inputs.parameters.gpu}}"
                          envFrom:
                            - configMapRef:
                                name: mlops-platform-env
                            - configMapRef:
                                name: "{{inputs.parameters.model_configmap}}"
                            - secretRef:
                                name: minio-tenant-secret
                          env:
                            - name: ARGO_WORKFLOW_UID
                              value: "{{workflow.uid}}"
                            - name: ARGO_WORKFLOW_NAME
                              value: "{{workflow.name}}"
                            - name: DOCKER_IMAGE_TAG
                              value: "{{inputs.parameters.image}}"
                            - name: DVC_DATA_VERSION
                              value: "{{inputs.parameters.dvc_data_version}}"
                            - name: REPLICAS
                              value: "{{inputs.parameters.replicas}}"

    # =========================================================================
    # WAIT: Stream logs while waiting for completion
    # =========================================================================
    - name: stream-and-wait
      inputs:
        parameters:
          - name: job_name
          - name: timeout
            default: "3600"
      outputs:
        parameters:
          - name: job_status
            valueFrom:
              path: /tmp/job_status.txt
      script:
        image: bitnami/kubectl:latest
        command: [bash]
        source: |
          set -e

          JOB_NAME="{{inputs.parameters.job_name}}"
          TIMEOUT="{{inputs.parameters.timeout}}"

          echo "PENDING" > /tmp/job_status.txt

          echo "=========================================="
          echo "ðŸ“‹ RayJob: $JOB_NAME"
          echo "=========================================="

          # Wait for job to initialize
          ELAPSED=0
          while [ $ELAPSED -lt 300 ]; do
            RAY_JOB_ID=$(kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobId}' 2>/dev/null || echo "")
            CLUSTER_NAME=$(kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.rayClusterName}' 2>/dev/null || echo "")
            DEPLOY_STATUS=$(kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobDeploymentStatus}' 2>/dev/null || echo "")

            if [ "$DEPLOY_STATUS" = "Failed" ]; then
              echo "âŒ RayJob deployment failed"
              kubectl describe rayjob -n mlops "$JOB_NAME"
              echo "FAILED" > /tmp/job_status.txt
              exit 1
            fi

            if [ -n "$RAY_JOB_ID" ] && [ -n "$CLUSTER_NAME" ]; then
              break
            fi

            echo "â³ Waiting for Ray cluster... (${ELAPSED}s)"
            sleep 5
            ELAPSED=$((ELAPSED + 5))
          done

          if [ -z "$RAY_JOB_ID" ] || [ -z "$CLUSTER_NAME" ]; then
            echo "âŒ Timeout waiting for Ray cluster"
            echo "FAILED" > /tmp/job_status.txt
            exit 1
          fi

          echo ""
          echo "ðŸš€ Job initialized:"
          echo "   Ray Job ID: $RAY_JOB_ID"
          echo "   Cluster:    $CLUSTER_NAME"
          echo ""

          # Wait for head pod to be ready
          echo "â³ Waiting for head pod..."
          kubectl wait --for=condition=ready pod \
            -l ray.io/cluster=${CLUSTER_NAME},ray.io/node-type=head \
            -n mlops --timeout=120s

          HEAD_POD=$(kubectl get pods -n mlops \
            -l ray.io/cluster=${CLUSTER_NAME},ray.io/node-type=head \
            -o jsonpath='{.items[0].metadata.name}')

          echo "   Head Pod:   $HEAD_POD"
          echo ""
          echo "=========================================="
          echo "ðŸ“ TRAINING LOGS"
          echo "=========================================="

          # Stream logs from head pod in background
          kubectl logs -n mlops -f "$HEAD_POD" -c ray-head 2>/dev/null &
          LOG_PID=$!

          # Poll for completion
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT ]; do
            JOB_STATUS=$(kubectl get rayjob -n mlops "$JOB_NAME" -o jsonpath='{.status.jobStatus}' 2>/dev/null || echo "")

            case "$JOB_STATUS" in
              "SUCCEEDED")
                sleep 3  # Let final logs flush
                kill $LOG_PID 2>/dev/null || true
                echo ""
                echo "=========================================="
                echo "âœ… Training completed successfully"
                echo "=========================================="
                echo "SUCCEEDED" > /tmp/job_status.txt
                exit 0
                ;;
              "FAILED"|"STOPPED")
                sleep 2
                kill $LOG_PID 2>/dev/null || true
                echo ""
                echo "=========================================="
                echo "âŒ Training failed: $JOB_STATUS"
                echo "=========================================="
                kubectl describe rayjob -n mlops "$JOB_NAME" | tail -50
                echo "FAILED" > /tmp/job_status.txt
                exit 1
                ;;
            esac

            sleep 5
            ELAPSED=$((ELAPSED + 5))
          done

          kill $LOG_PID 2>/dev/null || true
          echo "âŒ Timeout after ${TIMEOUT}s"
          echo "FAILED" > /tmp/job_status.txt
          exit 1
